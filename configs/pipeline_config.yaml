# ===PATH CONFIGURATION===
# All paths used throughout the pipeline are defined here for consistency
# These paths follow the pipeline flow: root_files -> inv_masses -> inv_masses_processed -> histograms
paths:  
  # Pipeline flow paths
  root_files_path: &root_files_path "/storage/agrp/netalev/data/root_files/"
  inv_masses_path: &inv_masses_path "/storage/agrp/netalev/data/inv_masses/"
  inv_masses_processed_path: &inv_masses_processed_path "/storage/agrp/netalev/data/inv_masses_processed/"
  histograms_path: &histograms_path "/storage/agrp/netalev/data/histograms/"
  
  # Supporting paths
  batch_job_file_ids_path: &batch_job_file_ids_path "/storage/agrp/netalev/data/batch_job_file_ids.json"
  testing_jobs_path: &testing_jobs_path "testing/testing_runs_bigger.json"
  logs_path: &logs_path "/storage/agrp/netalev/logs/"

# ===NAMES CONFIGURATION===
# Global names used throughout the pipeline
names:
  run_name: &run_name "cms-opendata-SingleElectronSingleMuon"
  output_filename: &output_filename "all_histograms.root"

tasks:
  do_parsing: false
  do_mass_calculating: false
  do_post_processing: false
  do_histogram_creation: true

testing_config:
  is_on: false #normal or random
  test_run_index: null
  testing_jobs_path: *testing_jobs_path

parsing_config:
  run_metadata:
    # ===BATCH JOB INDEX===
    batch_job_index: null
    run_name: *run_name
    total_batch_jobs: null

  pipeline_config:
    parse_mc: false
    
    parse_in_multiprocessing: false #important for cluster processing
    # ===AMOUNT OF PROCESSES TO PARSE FILES===
    max_parallel_workers: 4
    count_retries_failed_files: 3 
    # ===AMOUNT OF FILES TO LIMIT EACH YEAR (MAINLY TESTING PURPOSES)===
    limit_files_per_year: null #FOR TESTING - limit number of files per year
    # ===SOMETIMES FETCHING METADATA CAN BE LONG, SO SET A TIMEOUT===
    fetching_metadata_timeout: 60

    output_path: *root_files_path
    file_urls_path: *batch_job_file_ids_path
    
  
  atlasparser_config:
    # ===RELEVANT WHEN USED IN A RESTRICTED MEMORY ENV (A CLUSTER)===
    max_environment_memory_mb: 20000 
    # === SPECIFIC RECORD IDS (IF SPECIFIED, WILL IGNORE THE RELEASE YEARS) ===
    specific_record_ids:
      - 30529
      - 30562 
      - 30530 
      - 30563
    # ===RELEASE YEARS TO PARSE THE FILES FROM (IF EMPTY FETCHES ALL)===  
    release_years:
    # - 2024r-hi
    # - 2024r-pp
    
    max_threads: 8

    # ===A THRESHOLD FOR PREVENTING MEMORY OVERLOAD===
    chunk_yield_threshold_bytes: 5000000000 # 5GB 

    logging_path: *logs_path
    # ===SHOULD CREATE LOGGING AND DATA DIRECTORIES===
    create_dirs: true
    
    # ===THE NAMES FOR THE DATA TREES INSIDE THE ROOT FILES, CHANGES FROM EDU TO RESEARCH RELEASES===
    possible_tree_names:
    - CollectionTree
    - mini
    - analysis
    - Events
    show_progress_bar: true

  particle_counts:
    Electrons:
      min: 0
      max: 6
    Muons:
      min: 0
      max: 6
    Jets:
      min: 0
      max: 8
    Photons:
      min: 0
      max: 5

  kinematic_cuts:
    pt:
      min: 0
    eta:
      min: -5
      max: 5
    phi:
      min: -3.141592653589793
      max: 3.141592653589793

mass_calculate:
  # ===SLICE EVENTS AT TOP X PARTICLES BY THIS FIELD===
  field_to_slice_by: "pt" 
  # ===LIMIT COMBINATIONS CALCULATED, MAINLY FOR TESTING===
  limit_combinations: null
  # ===THRESHOLD FOR EMPTYING THE FS MAPPING (in bytes)===
  fs_mapping_threshold_bytes: 50000000  # 50MB default
  # ===INPUT DIRECTORY FOR THE ROOT FILES TO CALCULATE FROM===
  input_dir: *root_files_path
  # ===OUTPUT DIRECTORY FOR THE INVARIANT MASS ARRAYS===
  output_dir: *inv_masses_path
  # ===USE MULTIPROCESSING FOR PARALLEL FILE PROCESSING===
  use_multiprocessing: true
  # ===NUMBER OF WORKER PROCESSES (only used if use_multiprocessing is true)===
  max_workers: 4  # null = use CPU count
  # ===BATCH JOB CONFIGURATION (for distributed processing)===
  batch_job_index: null  # Set when running as batch job
  total_batch_jobs: null  # Set when running as batch job
  # ===PARTICLES TO CALCULATE INVARIANT MASS OUT OF===
  objects_to_calculate:
      - Electrons
      - Muons
      - Jets
      - Photons
  # ===COMBINATORICS===
  # ===MINIMUM AND MAXIMUM PARTICLES IN A COMBINATION===
  min_particles: 2
  max_particles: 4
  # ===COUNT FOR EACH PARTICLE IN A COMBINATION=== 
  min_count: 2
  max_count: 4
  # ===MINIMUM EVENTS PER FINAL STATE===
  min_events_per_fs: 100

post_processing:
  # ===INPUT DIRECTORY FOR THE IM ARRAY FILES===
  input_dir: *inv_masses_path
  # ===OUTPUT DIRECTORY FOR THE PROCESSED ARRAYS===
  output_dir: *inv_masses_processed_path
  # ===BIN WIDTHS TO USE FOR PEAK DETECTION (in GeV)===
  bin_widths_gev:
    - 10
    # - 10

histogram_creation:
  input_dir: *inv_masses_processed_path
  output_dir: *histograms_path
  bin_widths_gev:
    - 10

  # ===SINGLE OUTPUT FILE MODE (for batch jobs writing to shared file)===
  single_output_file: true
  output_filename: *output_filename
  
  exclude_outliers: true
  # ===BUMPNET COMPATIBILITY MODE===
  # When enabled: groups files by FS+IM signature, merges into single histogram,
  # and outputs BumpNet-compatible naming format (mass_<combo>_cat_<final_state>)
  use_bumpnet_naming: true