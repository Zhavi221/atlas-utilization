# ===PATH CONFIGURATION===
# All paths used throughout the pipeline are defined here for consistency
# These paths follow the pipeline flow: root_files -> inv_masses -> inv_masses_processed -> histograms
paths:  
  # Pipeline flow paths
  root_files_path: &root_files_path "/storage/agrp/netalev/data/root_files/"
  inv_masses_path: &inv_masses_path "/storage/agrp/netalev/archive/first_full_run/data/inv_masses_sample/"
  inv_masses_processed_path: &inv_masses_processed_path "/storage/agrp/netalev/data/inv_masses_processed/"
  histograms_path: &histograms_path "/storage/agrp/netalev/data/histograms/"
  
  # Supporting paths
  batch_job_file_ids_path: &batch_job_file_ids_path "/storage/agrp/netalev/data/batch_job_file_ids.json"
  testing_jobs_path: &testing_jobs_path "testing/testing_runs_bigger.json"
  jobs_logs_path: &jobs_logs_path "/storage/agrp/netalev/data/logs/"

# ===NAMES CONFIGURATION===
# Global names used throughout the pipeline
names:
  run_name: &run_name "test_new_algo"
  unified_histogram_filename: &unified_histogram_filename "test_new_algo.root"

# ===RUN METADATA===
# Runtime metadata for the pipeline execution
run_metadata:
  run_name: *run_name

# ===TASK ENABLEMENT===
# Control which tasks are executed in the pipeline
tasks:
  do_parsing: false
  do_mass_calculating: false
  do_post_processing: true
  do_histogram_creation: true

# ===TESTING CONFIGURATION===
# Settings for testing and development runs
testing_config:
  is_on: false 
  test_run_index: null
  testing_jobs_path: *testing_jobs_path
  limit_files_per_year: null  # FOR TESTING - limit number of files per year
  limit_combinations: null     # FOR TESTING - limit number of combinations to calculate

# ============================================================================
# TASK CONFIGURATIONS
# ============================================================================

# --- Parsing Task ---
# Extracts particle data from ROOT files using ATLAS parser
parsing_task_config:
  pipeline_config:
    # ===PATHS===
    output_path: *root_files_path
    file_urls_path: *batch_job_file_ids_path
    
    # ===PROCESSING CONFIGURATION===
    parse_mc: false
    use_multiprocessing: false  # Important: set to false for cluster processing
    parallel_processes: 4
    count_retries_failed_files: 3
    fetching_metadata_timeout: 60
  
  atlasparser_config:
    # ===PATHS===
    jobs_logs_path: *jobs_logs_path
    
    # ===MEMORY AND PERFORMANCE===
    env_threshold_memory_mb: 20000
    chunk_yield_threshold_bytes: 5000000000  # 5GB
    threads: 8
    
    # ===DATA SELECTION===
    specific_record_ids:
      # - 30529
      # - 30562 
      # - 30530 
      # - 30563
    release_years:  # Empty list - uncomment below to filter by year
    - 2024r-pp
    # - 2024r-hi
    
    # ===ROOT FILE TREE NAMES===
    # Tree names where data can be found in ROOT files
    possible_data_tree_names:
      - CollectionTree
      - mini
      - analysis
      - Events
    
    # ===SETTINGS===
    create_dirs: true
    show_progress_bar: true

  # ===FILTERING CONFIGURATION===
  # Particle count limits for event filtering
  particle_counts:
    Electrons:
      min: 0
      max: 6
    Muons:
      min: 0
      max: 6
    Jets:
      min: 0
      max: 8
    Photons:
      min: 0
      max: 5

  # Kinematic cuts applied to particles
  kinematic_cuts:
    pt:
      min: 0
    eta:
      min: -5
      max: 5
    phi:
      min: -3.141592653589793  # -π
      max: 3.141592653589793   # +π

# --- Mass Calculation Task ---
# Calculates invariant masses from particle combinations
mass_calculate_task_config:
  # ===PATHS===
  input_dir: *root_files_path
  output_dir: *inv_masses_path
  
  # ===PROCESSING CONFIGURATION===
  field_to_slice_by: "pt"
  use_multiprocessing: true
  parallel_processes: 4
  fs_chunk_threshold_bytes: 500000000  # 500MB
  
  # ===OBJECTS AND COMBINATORICS===
  objects_to_calculate:
    - Electrons
    - Muons
    - Jets
    - Photons
  
  # ===COMBINATORICS CONFIGURATION===
  min_particles_in_combination: 2
  max_particles_in_combination: 4
  min_count_particle_in_combination: 2
  max_count_particle_in_combination: 4
  min_events_per_fs: 100

# --- Post-Processing Task ---
# Post-processes invariant mass arrays (peak detection, removal, etc.)
post_processing_task_config:
  # ===PATHS===
  input_dir: *inv_masses_path
  output_dir: *inv_masses_processed_path
  
  # ===PROCESSING CONFIGURATION===
  # Bin width (in GeV) for peak detection and removal in post-processing
  peak_detection_bin_width_gev: 10

# --- Histogram Creation Task ---
# Creates histograms from processed invariant mass arrays
histogram_creation_task_config:
  # ===PATHS===
  input_dir: *inv_masses_processed_path
  output_dir: *histograms_path
  
  # ===PROCESSING CONFIGURATION===
  # Bin width (in GeV) for histogram binning
  bin_width_gev: 10
  
  # ===OUTPUT CONFIGURATION===
  single_output_file: true
  output_filename: *unified_histogram_filename
  exclude_outliers: true
  # When enabled, adapts histogram naming format for BumpNet input compatibility
  # Outputs histograms with naming: mass_<combo>_cat_<final_state>
  use_bumpnet_naming: true
