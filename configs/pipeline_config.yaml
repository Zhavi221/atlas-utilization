tasks:
  do_parsing: true
  do_mass_calculating: false

parsing_config:
  pipeline_config:
    parse_in_multiprocessing: true #important for cluster processing
    random_files: false #FEATURE reimplement
    retry_failed_files: true #FEATURE implement this
    max_parallel_workers: 4
    limit_files_per_year: 10 #FOR TESTING - limit number of files per year, set to -1 to parse all files
    fetching_metadata_timeout: 30
    output_path: "data/root_files"
  
  parser_config:
    # max_environment_memory_mb: 8192
    max_environment_memory_mb: 15000
    release_years: ["2024r-pp"] #when empty will parse all available years
    max_threads: 4
    # chunk_yield_threshold_bytes: 3000000000 #1GB 
    chunk_yield_threshold_bytes: 50000000 #FOR TESTING - 50MB for testing
    logging_path: "logs/"
    create_dirs: true
    possible_tree_names: ["CollectionTree", "mini", "analysis"] #TODO explain this paramter here or in docs,
  
  particle_counts:
    Electrons:
      min: 1
      max: 6
    Muons:
      min: 1
      max: 6
    Jets:
      min: 2
      max: 8
    Photons:
      min: 0
      max: 5

  kinematic_cuts:
    pt:
      min: 0
    eta:
      min: -5
      max: 5
    phi:
      min: -3.141592653589793
      max: 3.141592653589793

mass_calculate:
  # fs_mapping_threshold_bytes: 1000000000 #1GB 
  by_highest_pt: false #FEATURE 
  fs_mapping_threshold_bytes: 3000 #FOR TESTING - 500MB for testing
  input_dir: "data/root_files"
  output_dir: "data/inv_masses"
  objects_to_calculate:
      - Electrons
      - Muons
      - Jets
      - Photons
  min_particles: 2
  max_particles: 4
  min_count: 2
  max_count: 4
