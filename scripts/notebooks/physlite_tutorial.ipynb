{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da3ffc89-318b-46d6-ae88-67d21e56ffa7",
   "metadata": {},
   "source": [
    "# How to use a PHYSLITE file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287c710b",
   "metadata": {},
   "source": [
    "For the ATLAS Open Data for Research, we have released hundreds of datasets in PHYSLITE format. In this notebook we are going to show you how to access the event and variables, and how to do a basic analysis using `uproot` and `awkward` arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88eaedc5-e589-459e-aaff-467c9b480af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries\n",
    "import copy # copy variables\n",
    "import os   # manage paths\n",
    "\n",
    "import uproot   # use of root files\n",
    "import awkward as ak    # nested, variable sized data\n",
    "import vector   # lorentz vectors\n",
    "vector.register_awkward()\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import tqdm # progress bars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76acc26",
   "metadata": {},
   "source": [
    "In this notebook we are using a dataset from `mc20_13TeV.410470.PhPy8EG_A14_ttbar_hdamp258p75_nonallhad.deriv.DAOD_PHYSLITE.e6337_s3681_r13167_p5855`. To run this notebook locally, please download a dataset from this container and substitute the file and path in the `filename` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7f9a793-d084-4235-a8af-3b922df662f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mc20_13TeV.410470.PhPy8EG_A14_ttbar_hdamp258p75_nonallhad.deriv.DAOD_PHYSLITE.e6337_s3681_r13167_p5855\n",
    "filename = \"root://eospublic.cern.ch//eos/opendata/atlas/rucio/data16_13TeV/DAOD_PHYSLITE.37019878._000001.pool.root.1\"\n",
    "filename = \"example_data/DAOD_PHYSLITE.37001626._000002.pool.root.1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3617b2-20c4-4bde-867f-60a4c9019be1",
   "metadata": {},
   "source": [
    "## Read PHYSLITE with uproot\n",
    "We can open a `TFile` using [`uproot.open`](https://uproot.readthedocs.io/en/latest/uproot.reading.open.html). To check the Ttree objects in the file we use the `.keys()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TTree objects inside the ROOT file:')\n",
    "for ii in uproot.open(filename).keys():\n",
    "    print('-',ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b1f720",
   "metadata": {},
   "source": [
    "To get directly a `TTree`, pass a dictionary with `{filename: treename}`. `CollectionTree` is the TTree with the events information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c970f65b-7944-40c1-b6cc-6e3734b20242",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = uproot.open({filename: \"CollectionTree\"})\n",
    "tree\n",
    "print([i for i in list(tree.keys()) if 'Electron' in i])\n",
    "print([i for i in list(tree.keys()) if 'pt' in i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa712142-2601-4872-9b85-e5979fec5fb1",
   "metadata": {},
   "source": [
    "### List branches\n",
    "Most of the data in a PHYSLITE is in the branches with \"AuxDyn\" in their name. This branches are type `vector<int>` or `vector<float>`, i.e. a vector of integers or floats. We can see all the branches with the `.show()` method. Here, we are only showing the first 10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea8bb7-2ad7-4509-b126-abd4ec9e4e78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Display only the first 10 branches\n",
    "first_10_branches = list(tree.keys())[:10]\n",
    "tree.show(filter_name=first_10_branches, name_width=50, typename_width=50, interpretation_width=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320ce1fe-01bf-4041-8649-da24b2676039",
   "metadata": {},
   "source": [
    "### Load branches into awkward and numpy arrays\n",
    "\n",
    "We can get a branch of a TTree by using `[branch_name]` and calling `.array()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79aad2b1-a824-4ac1-8c66-ff2bd1457c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "el_pt = tree[\"AnalysisElectronsAuxDyn.pt\"].array()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3afa7a0-d6ce-4d37-8ef8-82f1b8d8d536",
   "metadata": {},
   "source": [
    "These vector branches are represented using awkward arrays. In this case, we are getting the transverse momentum ($p_T$) of all the electrons in each event. For each event we have a variable lenght of electrons, in a total of 120,000 events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d18444-2e50-47fb-86d7-d5b5a402a147",
   "metadata": {},
   "outputs": [],
   "source": [
    "el_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b347b0",
   "metadata": {},
   "source": [
    "> Note: `120000 * var * float32` means: 120000 events, made by arrays of *var*iable lenght, comprised by floats (that represent the $p_T$ of the electrons in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91569ce-7653-46b3-9a1e-6ee80aa21d78",
   "metadata": {},
   "source": [
    "For plotting the $p_T$ distribution, we flatten the array to get the $p_T$ of all the electrons in a 1D array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cd04b4-0c8a-4bb2-a53d-749def333754",
   "metadata": {},
   "outputs": [],
   "source": [
    "el_pt_np = ak.flatten(el_pt).to_numpy()\n",
    "print(f'Total number of electrons in 120,000 events: {len(el_pt_np):,}')\n",
    "el_pt_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a6d3e4-ea6d-48d4-abfd-9b86e63b90b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(el_pt_np, bins=100)\n",
    "plt.title('$p_T$ distribution of all $e$')\n",
    "plt.xlabel('$p_T$')\n",
    "plt.ylabel('Number of electrons')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d4cb52-8343-4ef3-87db-b8a3d8477500",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Simple analysis\n",
    "\n",
    "To demonstrate the use of a PHYSLITE, we will work trough a very basic $t\\bar{t}$ analysis. Inspired by the [Analysis Grand Challenge (AGC)](https://agc.readthedocs.io/en/latest/), the goal is to reconstruct the hadronically decaying top quark from semi-leptonic $t\\bar{t}$ events. This means identifying the three jets that originated from the hadronic decay of one top quark and combining their information to estimate the quark's original properties.\n",
    "\n",
    "![](img/ttbar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6bac7-2bd4-4a26-a3c1-0ab2aa52e622",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Collect branches into records\n",
    "Doing the analysis using the arrays showed before would be inefficient. We are going to use the `.zip()` method from the `awkward` library. This let us can zip multiple arrays in a single structure.\n",
    "\n",
    "For the analysis we need some information from our PHYSLITE file. We are going to get $p_T$, the pseudorapidity ($\\eta$), and the azimuthal angle ($\\phi$). for electrons, muons, and jets. For jets, we are also getting their mass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5bc7dd9-5dc1-4a52-bd79-387090c5e5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "electrons = ak.zip(\n",
    "    {\n",
    "        \"pt\": tree[\"AnalysisElectronsAuxDyn.pt\"].array(),\n",
    "        \"eta\": tree[\"AnalysisElectronsAuxDyn.eta\"].array(),\n",
    "        \"phi\": tree[\"AnalysisElectronsAuxDyn.phi\"].array(),\n",
    "    }\n",
    ")\n",
    "\n",
    "muons = ak.zip(\n",
    "     {\n",
    "        \"pt\": tree[\"AnalysisMuonsAuxDyn.pt\"].array(),\n",
    "        \"eta\": tree[\"AnalysisMuonsAuxDyn.eta\"].array(),\n",
    "        \"phi\": tree[\"AnalysisMuonsAuxDyn.phi\"].array(),\n",
    "    }\n",
    ")\n",
    "\n",
    "jets = ak.zip(\n",
    "     {\n",
    "        \"pt\": tree[\"AnalysisJetsAuxDyn.pt\"].array(),\n",
    "        \"eta\": tree[\"AnalysisJetsAuxDyn.eta\"].array(),\n",
    "        \"phi\": tree[\"AnalysisJetsAuxDyn.phi\"].array(),\n",
    "        \"mass\": tree[\"AnalysisJetsAuxDyn.m\"].array(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48fb0b3-064d-459a-91f8-21829d306a05",
   "metadata": {},
   "source": [
    "We have structured our information into record arrays, where each record represents the properties of electrons/muons/jets detected in various events.\n",
    "\n",
    "If we check the estructure of the electrons, for each electron within each event, we record three properties: \n",
    "\n",
    "- The outermost structure is a list, where each element corresponds to a single event. This means each item in this list represents all the electrons detected for a particular event.\n",
    "- Inside each of these event lists, we have zero or more records. Each record is a dictionary that details the properties of a single electron. Specifically, the records contain:\n",
    "    - pt: The transverse momentum of the electron, measured in electron volts (eV), indicating the component of the momentum perpendicular to the beam direction.\n",
    "    - eta: The pseudorapidity, which is a spatial coordinate describing the angle of the particle relative to the beam axis. It helps in understanding the direction of the particle's movement.\n",
    "    - phi: The azimuthal angle in the transverse plane, providing the direction of the particle around the beam axis.\n",
    "\n",
    "For example, an empty list [] indicates an event where no electrons were detected. A non-empty list, such as [{pt: 7.65e+03, eta: -1.33, phi: -0.0518}, {pt: 3.94e+03, eta: ..., ...}], signifies an event where two electrons were detected, each with its respective $p_T$, $\\eta$, and $\\phi$ values detailed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6629906-6624-4542-b8bc-a960795aab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "electrons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc76b899",
   "metadata": {},
   "source": [
    "The dataset contains a total of 90,000 variable-length records, each structured as follows:\n",
    "\n",
    "```\n",
    "type: 90000 * var * {\n",
    "    pt: float32,\n",
    "    eta: float32,\n",
    "    phi: float32\n",
    "}\n",
    "```\n",
    "This indicates that we have a dynamic array of up to 90,000 events, and for each event, there can be a variable number of electrons detected, with each electron's properties ($p_T$, $\\eta$, $\\phi$) stored as 32-bit floating-point numbers.\n",
    "\n",
    "This organization allows for efficient storage and processing of the physical properties of electrons across a large number of particle collision events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef9be37-25c3-4e35-bffd-1a4d506b648c",
   "metadata": {},
   "source": [
    "We can access the fields conveniently via attribute or dictionary access:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b8e413-e12c-4765-9320-dfcf48446be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "electrons.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12820420-37a7-4339-96d1-fdcf4a604112",
   "metadata": {},
   "outputs": [],
   "source": [
    "electrons[\"pt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2188be26-5d43-4287-96da-af178d539b4c",
   "metadata": {},
   "source": [
    "For the jets we'll also need BTagging information. Technically this would be provided by ElementLinks (cross references), but here in PHYSLITE we have exactly one btagging value for each jet in the `BTagging_AntiKt4EMPFlowAuxDyn.DL1dv01_pb` branch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da5a12bc-1b35-40a7-b13e-3eaff036d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "btag_prob = tree[\"BTagging_AntiKt4EMPFlowAuxDyn.DL1dv01_pb\"].array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc9a399-08b3-4398-8472-1cdccd6be21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ak.all(ak.num(btag_prob) == ak.num(jets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a99b38-c8a3-45db-8225-2eb7a4541129",
   "metadata": {},
   "source": [
    "Since we have a value for each jet, we can just attach this as an additional field to our jets as we would do in a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cff0a36-6799-418d-8ace-55f700370b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "jets[\"btag_prob\"] = btag_prob\n",
    "jets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3879f8-4d89-4338-861e-d531a42c8e29",
   "metadata": {},
   "source": [
    "To facilitate convenient event selections, we organize all detected particle types—electrons, muons, and jets—into a single record array named events. This structure allows us to access all relevant data for each event in a unified manner.\n",
    "\n",
    "Each entry in the events array corresponds to a specific collision event and contains the records for electrons, muons, and jets. It's important to note that we use `depth_limit=1` during this organization process. This parameter ensures that while the first dimension (representing individual events) is uniform in length across the dataset, the second dimension (index 1) can accommodate lists of arbitrary lengths to account for the varying number of particles detected per event.\n",
    "\n",
    "The data is organized by electrons, muons, jets. Each of these keys within an event's record holds the list of records, defined above, for the respective particle type. If a particular type of particle was not detected in an event, its list will be empty ([]). For instance, an event with no electrons but with muons and jets will have an empty list for electrons and populated lists for muons and jets.\n",
    "\n",
    "An example entry might look like this:\n",
    "\n",
    "```\n",
    "{\n",
    "  Electrons: [{pt: ..., eta: ..., phi: ...}, ...],\n",
    "  Muons: [{pt: ..., eta: ..., phi: ...}, ...],\n",
    "  Jets: [{pt: ..., eta: ..., phi: ..., mass: ..., btag_prob: ...}, ...]\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafffbfa-b82a-4010-bb76-742f2e256a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = ak.zip({\"Electrons\": electrons, \"Muons\": muons, \"Jets\": jets}, depth_limit=1)\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4374748",
   "metadata": {},
   "source": [
    "This organizational scheme, encapsulated as:\n",
    "```\n",
    "type: 90000 * {\n",
    "    Electrons: var * {\n",
    "        pt: float32,\n",
    "        eta: float32,\n",
    "        phi: float32\n",
    "    },\n",
    "    Muons: var * {\n",
    "        pt: float32,\n",
    "        eta: float32,\n",
    "        phi: float32\n",
    "    },\n",
    "    Jets: var * {\n",
    "        pt: float32,\n",
    "        eta: float32,\n",
    "        phi: float32,\n",
    "        mass: float32,\n",
    "        btag_prob: float32\n",
    "    }\n",
    "}\n",
    "```\n",
    "describes a dataset of 90,000 events, where each event can contain a variable number of Electrons, Muons, and Jets. Each particle's properties are stored as 32-bit floating-point numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c60f079-4d85-4929-bee5-35a029040a83",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Event and object selection\n",
    "- **At least 4 Jets Required:** In a $t\\bar{t}$ event, one top quark decays hadronically (into three jets) while the other decays leptonically (into a lepton and a b-jet alongside a neutrino). The requirement for at least four jets reflects the need to capture both decay channels. Specifically, one jet is expected from the leptonic decay (the b-jet) and three from the hadronic decay.\n",
    "\n",
    "- **Exactly One Electron or Muon:** This particle should have reasonably high $p_T$ and be centrally located within the detector (indicating its $\\eta$ is within a central range). The presence of exactly one high-$p_T$, centrally-located electron or muon ensures we're observing a semi-leptonic $t\\bar{t}$ decay, where one top quark decays into a lepton (electron or muon), a neutrino, and a b-jet. This criterion helps filter events that closely match the expected signature of a $t\\bar{t}$ event.\n",
    "\n",
    "- **B-tagging with 85% Working Point:** B-tagging is a technique used to identify jets originating from b-quarks. The \"85% working point\" refers to a specific threshold in the b-tagging algorithm that offers an 85% probability of correctly identifying b-jets. Choosing this working point balances the need for high b-jet identification efficiency with the control of mistakenly tagging light-quark or gluon jets as b-jets (misidentification rate).\n",
    "\n",
    "- **At Least 2 B-jets:** Since both top quarks in a $t\\bar{t}$ event decay into a b-quark (one directly in the hadronic decay and one as part of the leptonic decay chain), identifying at least two b-jets in an event is crucial. This ensures that the selection process captures the events that likely represent the decay products of a pair of top quarks.\n",
    "\n",
    "By adhering to these selection criteria, the analysis aims to filter the dataset for events that are most representative of semi-leptonic $t\\bar{t}$ decays, facilitating a focused and efficient study of the hadronically decaying top quark."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb12a18-0e57-4dc5-85d2-45ee4f24ff06",
   "metadata": {},
   "source": [
    "#### Basic object selections\n",
    "\n",
    "The object selection is done using boolean masks—a way to select only those elements that meet our criteria. Selections work like in `numpy`, by passing a boolean mask like `[mask]`. A boolean mask is essentially an array where each element is either True (if the condition is met) or False (if the condition is not met). When applied to the dataset, it filters out only the True elements.\n",
    "\n",
    "We define a condition (e.g., electrons.pt > 30 * GeV) to create a mask. This condition checks if the transverse momentum of each electron is greater than 30 GeV (where GeV = 1000. is a unit conversion factor). The result is a boolean mask array indicating with True or False whether each electron in each event meets the condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb8a81d-002f-4d01-a06c-776cc88eca97",
   "metadata": {},
   "outputs": [],
   "source": [
    "GeV = 1000.\n",
    "mask = electrons.pt > 30 * GeV\n",
    "mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a5d155",
   "metadata": {},
   "source": [
    "Applying the mask to the electrons array (electrons[mask]) filters out only those electrons that meet the condition. If none meet the condition, the result for that event is an empty list. This process generalizes to lists, allowing us to work with vector branches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c9cdd6-a2be-4d4a-9def-623101468a3c",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "electrons[mask]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a21f472",
   "metadata": {},
   "source": [
    "We define functions (selected_electrons, selected_muons, selected_jets) to encapsulate the selection logic. These functions return only the particles from each event that meet both conditions:\n",
    "- Their $p_T$ is greater than 30 GeV.\n",
    "- Their $\\eta$ is within a certain range ($|\\eta| < 2.47$), ensuring they are centrally located within the detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "86bb14d7-8451-4f1a-ae3b-cbe1ceba71c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selected_electrons(el):\n",
    "    return el[(el.pt > 30 * GeV) & (abs(el.eta) < 2.47)]\n",
    "\n",
    "def selected_muons(mu):\n",
    "    return mu[(mu.pt > 30 * GeV) & (abs(mu.eta) < 2.47)]\n",
    "\n",
    "def selected_jets(j):\n",
    "    return j[(j.pt > 30 * GeV) & (abs(j.eta) < 2.47)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92b0535-c788-48fd-983d-889b0b843254",
   "metadata": {},
   "source": [
    "We apply these selections to all our objects in the `events` record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ec062be4-774e-4c54-88cc-d6e43f399fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"Electrons\"] = selected_electrons(electrons)\n",
    "events[\"Muons\"] = selected_muons(muons)\n",
    "events[\"Jets\"] = selected_jets(jets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b72588c-a4c7-4605-8e64-326ef29a0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Number of electrons before selection: {ak.count(electrons.pt):,}')\n",
    "print(f'Number of electrons after selection: {ak.count(events.Electrons.pt):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0605916d-4e7c-4333-ac95-7c3aaf6936cb",
   "metadata": {},
   "source": [
    "#### Lorentz vectors\n",
    "The vector package in Python provides tools to treat collections of particle properties as vectors. This is particularly useful for performing geometric and kinematic calculations, such as transformations and invariant mass calculations. \n",
    "\n",
    "We start by converting the properties of particles (Electrons, Muons, Jets) into Lorentz vectors. This involves associating their physical properties (e.g., transverse momentum, pseudorapidity, azimuthal angle) with the components of a vector. The function `vector.awk()` is applied to the properties of Electrons, Muons, and Jets. This operation effectively converts the data structure holding the particles' properties into one that supports vector operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4febca66-c97b-44dc-8f6e-6ad85165131c",
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"Electrons\"] = vector.awk(events.Electrons)\n",
    "events[\"Muons\"] = vector.awk(events.Muons)\n",
    "events[\"Jets\"] = vector.awk(events.Jets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a1aeab-d400-47a4-a104-e5b17e186f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.Electrons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57877984",
   "metadata": {},
   "source": [
    "After conversion, you can access specific vector components directly. For instance, accessing the $p_x$ component (the x-component of the momentum vector) of each electron becomes straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eeb08d-7173-4eab-93e8-1c5fbc0be43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "events.Electrons.px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b823560-a7c8-49db-898f-e6a401958352",
   "metadata": {},
   "source": [
    "#### Overlap removal\n",
    "\n",
    "Overlap removal is an essential step in particle physics analyses to ensure that the same physical object is not misidentified as multiple types of particles. When particles like electrons and jets are detected close to each other in the detector, it can create ambiguity about their identities. This section explains how to identify and remove such overlaps, focusing on the overlap between electrons and jets.\n",
    "\n",
    "##### Understanding Overlap Removal\n",
    "1. **Identifying Overlaps with Cartesian Product**:\n",
    "\n",
    "    The process begins by considering all possible pairs (combinations) of electrons and jets within each event. This is known as creating a Cartesian product.\n",
    "    `ak.cartesian([events.Jets, events.Electrons], nested=True)` generates all combinations of jets and electrons. The `nested=True` parameter adds an additional dimension to the array, which represents each possible pair of jet and electron. \n",
    "\n",
    "    The result of `ak.cartesian` is then split into two arrays (`jj` for jets and `ee` for electrons) using `ak.unzip`. This effectively separates the pairs into corresponding jets and electrons arrays but keeps them linked by their indices within these arrays.\n",
    "\n",
    "2. **Calculating the Separation with $\\Delta R$**:\n",
    "\n",
    "    The next step involves calculating the separation between each jet-electron pair. This separation is quantified using a metric called $\\Delta R$, which combines differences in their azimuthal angle ($\\phi$) and pseudorapidity ($\\eta$) into a single distance measure. `jj.deltaR(ee)` calculates the $\\Delta R$ between each jet and electron in the pairs generated. Plotting the histogram of $\\Delta R$ values for all jet-electron pairs gives insight into how closely jets and electrons are located to each other in the detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f1b62f-2b05-4f47-abd9-f60be305ea2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "jj, ee = ak.unzip(ak.cartesian([events.Jets, events.Electrons], nested=True))\n",
    "print(jj)\n",
    "print(ee)\n",
    "# plt.hist(ak.flatten(jj.deltaR(ee), axis=None).to_numpy(), bins=100)\n",
    "# plt.xlabel(\"$\\Delta R(j, e)$ (for all jet - electron pairs)\")\n",
    "# plt.ylabel(\"Count of Jet-Electron Pairs\")\n",
    "# plt.title('Distribution of $\\Delta R$ Between Jets and Electrons')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e45f8fe",
   "metadata": {},
   "source": [
    "3. **Defining and Applying Overlap Removal Criteria**:\n",
    "    A common criterion for overlap removal is to exclude jets that are within a certain $\\Delta R$ distance from an electron, typically $\\Delta R < 0.4$.\n",
    "    The function `no_overlap(obj1, obj2, deltaR=0.4)` checks for each jet if there is any electron within a $\\Delta R$ of 0.4. It uses `ak.all(obj1.deltaR(obj2) > deltaR, axis=-1)` to return a boolean mask where True indicates a jet does not overlap any electron by this criterion. This mask can then be applied to the jets array to filter out those jets that are too close to electrons, ensuring they are not double-counted as both jets and electrons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "99d009f5-7812-4bd8-a130-49976dfa5f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_overlap(obj1, obj2, deltaR=0.4):\n",
    "    obj1, obj2 = ak.unzip(ak.cartesian([obj1, obj2], nested=True))\n",
    "    return ak.all(obj1.deltaR(obj2) > deltaR, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf21abab",
   "metadata": {},
   "source": [
    "After defining the no_overlap function, it's used to create a mask for jets that do not overlap with electrons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcab445-be56-40d4-9584-74397e5c9fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_overlap(events.Jets, events.Electrons) # mask for each jet if it has no overlap with any electron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678f3ee8",
   "metadata": {},
   "source": [
    "This mask is then applied to the jets in the events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79cda0ba-6300-4e87-9d68-90d4487c6412",
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"Jets\"] = events.Jets[no_overlap(events.Jets, events.Electrons)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607d4042",
   "metadata": {},
   "source": [
    "This step updates the events dataset to only include jets that have passed the overlap removal criteria, ensuring a cleaner separation of particle types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca484a2b-5025-456d-983f-9656fa081255",
   "metadata": {},
   "source": [
    "#### Apply event selection\n",
    "After cleaning the dataset through overlap removal, applying event selection criteria helps isolate the events that are most relevant to the specific analysis goal. In this case, the criteria are tailored for $t\\bar{t}$ analysis, and were explained above:\n",
    "- At least 4 Jets\n",
    "- Exactly One Lepton (Electron or Muon)\n",
    "- At Least Two B-tagged Jets with Prob > 0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82a1ee4-4a41-4673-9d3c-077fbde99b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "events[\"Jets\", \"is_bjet\"] = events.Jets.btag_prob > 0.85\n",
    "\n",
    "events = events[\n",
    "    (ak.num(events.Jets) >= 4) # at least 4 jets\n",
    "    & ((ak.num(events.Electrons) + ak.num(events.Muons)) == 1) # exactly one lepton\n",
    "    & (ak.num(events.Jets[events.Jets.is_bjet]) >= 2) # at least two btagged jets with prob > 0.85\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa9f5b-89ad-4ade-a8b1-d3b97fdd7548",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Initially we had 120,000 events. After the event selection we have {len(events):,} events')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9013c140-8a58-4a84-8c41-8e035202e005",
   "metadata": {},
   "source": [
    "### Top quark reconstruction\n",
    "\n",
    "As we progress through our $t\\bar{t}$ analysis, the next critical step involves reconstructing the top quark from the decay products observed in our events. This section outlines a streamlined approach to piecing together the decay signature of the top quark from jet combinations, focusing on key criteria that align with the characteristics of top quark decays.\n",
    "\n",
    "#### Procedure for Top Quark Reconstruction:\n",
    "1. **Combining Jets**:\n",
    "    We start by generating all possible combinations of three jets within each event. This step is foundational, considering the typical hadronic decay of a top quark results in three jets.\n",
    "\n",
    "2. **Incorporating B-jets**:\n",
    "    To refine our combinations, we require that at least one jet in each combination is b-tagged (`is_bjet`). This reflects the decay pathway of the top quark, where one jet is expected to originate from a b quark.\n",
    "    \n",
    "3. **Identifying the Best Candidate**:\n",
    "    Among these combinations, we then identify the one with the highest total $p_T$. This criterion helps select the combination most likely to represent the decay products of a top quark, based on the assumption that the decay of a massive particle like the top quark would produce high-momentum jets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082ea56c",
   "metadata": {},
   "source": [
    "### Implementation Through the mjjj Function:\n",
    "- **Creating Combinations**: Utilizes `ak.combinations(jets, 3)` to form every 3-jet group.\n",
    "- **Unpacking Jets**: Through `ak.unzip(candidates)`, the individual jets in each combination are extracted.\n",
    "- **Filtering for B-jets**: Ensures combinations include at least one b-jet by evaluating `(j1.is_bjet + j2.is_bjet + j3.is_bjet) > 0`.\n",
    "- **4-Momentum Calculation**: Computes the total 4-momentum for each jet trio, `candidates[\"p4\"] = j1 + j2 + j3`.\n",
    "- **Selection of Top Candidate**: Chooses the jet combination with the highest pt as the top quark candidate, extracting its mass for the reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96ea14fc-1904-4dfe-ad07-85ddce7d9ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mjjj(jets):\n",
    "    candidates = ak.combinations(jets, 3)\n",
    "    j1, j2, j3 = ak.unzip(candidates)\n",
    "    has_b = (j1.is_bjet + j2.is_bjet + j3.is_bjet) > 0\n",
    "    candidates[\"p4\"] = j1 + j2 + j3\n",
    "    candidates = candidates[has_b]\n",
    "    candidates = candidates[ak.argmax(candidates.p4.pt, axis=1, keepdims=True)]\n",
    "    return candidates.p4.mass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe2cca5",
   "metadata": {},
   "source": [
    "Visualizing these masses through a histogram provides insights into the effectiveness of the reconstruction method and the characteristics of the top quark decays within our dataset. The most prominent feature to look for is a peak in the distribution that corresponds to the known mass of the top quark. The mass of the top quark is approximately 172.76 GeV/c². Therefore, a peak around this value indicates successful reconstruction of top quarks from the decay products."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c322ccf-2c6a-4000-9206-7e589754c177",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(ak.flatten(mjjj(events.Jets) / GeV, axis=None), bins=100)\n",
    "plt.xlabel(\"Reconstructed Top Quark Mass (GeV)\")\n",
    "plt.ylabel(\"Number of Events\")\n",
    "plt.title(\"Distribution of Reconstructed Top Quark Mass\")\n",
    "plt.axvline(172.76, color='r', linestyle='dashed', linewidth=2, label='Expected Top Quark Mass')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa11948-6a47-4537-a781-30f0aed3fa4b",
   "metadata": {},
   "source": [
    "### Run on larger number of files\n",
    "\n",
    "When scaling up data analysis to handle larger datasets, especially in high-energy physics where datasets can be enormous, managing memory usage becomes crucial to prevent running out of memory (OOM) errors. Here's a clearer explanation of the strategies mentioned for handling large-scale data processing efficiently:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76d902e",
   "metadata": {},
   "source": [
    "#### Chunking the Processing\n",
    "This approach involves dividing the dataset into smaller, manageable pieces or \"chunks\" and processing each chunk sequentially. After processing a chunk, the results can be aggregated (e.g., accumulating in a histogram or ntuple), and the memory used by the chunk can be released before moving on to the next chunk. This method helps in managing memory usage effectively by ensuring that only a portion of the data is held in memory at any given time.\n",
    "\n",
    "- Advantages: Simple to implement and can significantly reduce memory usage.\n",
    "- Use Case: Particularly useful when operations on individual chunks are independent and can be aggregated easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c8b71a",
   "metadata": {},
   "source": [
    "#### Distributed Processing\n",
    "Distributed processing involves spreading the data and computations across multiple machines or processors. This not only helps in managing memory by leveraging the collective memory of multiple systems but also can speed up the processing by executing tasks in parallel. We won't discuss distributed processing in this tutorial, but there are nice possibilities to do this while still staying interactive by using [`dask`](https://www.dask.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed599e2",
   "metadata": {},
   "source": [
    "#### Processing Data in Chunks with Awkward Array\n",
    "For the specific case of processing large datasets of particle physics events, where the analysis might discard a significant number of events and only a subset of data columns are retained, processing data in chunks becomes highly efficient. Here's how you can do it:\n",
    "\n",
    "- **Process Each File Separately**: Instead of loading the entire dataset into memory, process each file one at a time. This limits the amount of data in memory to what's contained in a single file.\n",
    "- **Use `ak.to_packed` for Memory Efficiency**: After applying event selection and filtering out unnecessary data, the ak.to_packed function can be used to further reduce memory usage. This function optimizes the memory layout of the Awkward Array by eliminating unused spaces (from masks and indices) and ensuring that only the memory needed for the retained data is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a14d0c2-49fd-439f-a170-9da4e3db35a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_usage_kiB = ak.to_packed(events).nbytes / 1024\n",
    "print(f\"Memory usage: {memory_usage_kiB:.5} kiB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c0bef3",
   "metadata": {},
   "source": [
    "This calculation gives you an estimate of the memory usage after compaction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743d7cc3-07bc-4b1a-87ea-55a1f5aa1e7a",
   "metadata": {},
   "source": [
    "#### Organize code into functions\n",
    "First, we structure everything a bit more nicely into functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24e1347",
   "metadata": {},
   "source": [
    "##### Defining a Schema\n",
    "The schema dictionary outlines the data structure expected from the input files. It maps each particle type (Electrons, Muons, Jets, and BTagging information) to the relevant attributes that will be read and processed. This schema is crucial for dynamically handling different data fields across various particle types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c05d98f8-348d-42a8-a907-669301b43e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"Electrons\": [\n",
    "        \"pt\", \"eta\", \"phi\",\n",
    "    ],\n",
    "    \"Muons\": [\n",
    "        \"pt\", \"eta\", \"phi\",\n",
    "    ],\n",
    "    \"Jets\": [\n",
    "        \"pt\", \"eta\", \"phi\", \"m\"\n",
    "    ],\n",
    "    \"BTagging_AntiKt4EMPFlow\": [\n",
    "        \"DL1dv01_pb\",\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5900ed23",
   "metadata": {},
   "source": [
    "##### `read_events` Function\n",
    "Reads data from a file according to the specified schema, organizing the data into a structured format suitable for analysis.\n",
    "\n",
    "**Process:**\n",
    "- Opens a file using uproot and iterates over the schema to read specified fields for each particle type.\n",
    "- Uses `ak.zip` to combine the fields into structured arrays, preserving the relationship between different attributes of each particle type.\n",
    "- Returns a structured awkward array (`ak.zip(events, depth_limit=1)`) that encapsulates the event data, allowing for efficient, high-level operations on the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6e19997e-93fa-4e14-b7ce-078b7db95c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_events(filename, schema):\n",
    "    with uproot.open({filename: \"CollectionTree\"}) as tree:\n",
    "        events = {}\n",
    "        for objname, fields in schema.items():\n",
    "            base = objname\n",
    "            if objname in [\"Electrons\", \"Muons\", \"Jets\"]:\n",
    "                base = \"Analysis\" + objname\n",
    "                ak_zip = vector.zip\n",
    "            else:\n",
    "                ak_zip = ak.zip\n",
    "            arrays = tree.arrays(\n",
    "                fields,\n",
    "                aliases={field: f\"{base}AuxDyn.{field}\" for field in fields},\n",
    "            )\n",
    "            arrays = ak_zip(dict(zip(arrays.fields, ak.unzip(arrays))))\n",
    "            events[objname] = arrays\n",
    "        return ak.zip(events, depth_limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e83c10-2ca8-4670-a19e-275b39d1a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = read_events(filename, schema)\n",
    "events"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cc3681",
   "metadata": {},
   "source": [
    "##### `processed` Function\n",
    "Applies a series of processing steps to the events data to prepare it for analysis. This includes applying selection criteria and organizing data for efficient memory usage.\n",
    "\n",
    "**Process:**\n",
    "- Makes a shallow copy of the events to avoid mutating the original data.\n",
    "- Adds a `btag_prob` field to Jets based on BTagging information.\n",
    "- Applies selection functions (`selected_electrons`, `selected_muons`, `selected_jets`) to filter particles based on specific criteria (e.g., transverse momentum and pseudorapidity).\n",
    "- Removes overlapping jets with selected electrons to avoid double counting.\n",
    "- Flags jets as b-tagged jets (`is_bjet`) based on their b-tagging probability.\n",
    "- Applies event selection criteria to filter the events further, retaining those with at least four jets, exactly one lepton (electron or muon), and at least two b-tagged jets.\n",
    "- Compacts the data using ak.`to_packed` to reduce memory usage, discarding unnecessary indices and masks.\n",
    "\n",
    "It returns a processed and compacted dataset, ready for further analysis, with significantly reduced memory footprint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1fffb3d5-9805-4cba-afa3-f7e89a987d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processed(events):\n",
    "    events = copy.copy(events) # shallow copy\n",
    "    events[\"Jets\", \"btag_prob\"] = events.BTagging_AntiKt4EMPFlow.DL1dv01_pb\n",
    "    events[\"Electrons\"] = selected_electrons(events.Electrons)\n",
    "    events[\"Muons\"] = selected_muons(events.Muons)\n",
    "    events[\"Jets\"] = selected_jets(events.Jets)\n",
    "    events[\"Jets\"] = events.Jets[no_overlap(events.Jets, events.Electrons)]\n",
    "    events[\"Jets\", \"is_bjet\"] = events.Jets.btag_prob > 0.85\n",
    "    events = events[\n",
    "        (ak.num(events.Jets) >= 4) # at least 4 jets\n",
    "        & ((ak.num(events.Electrons) + ak.num(events.Muons)) == 1) # exactly one lepton\n",
    "        & (ak.num(events.Jets[events.Jets.is_bjet]) >= 2) # at least two btagged jets with prob > 0.85\n",
    "    ]\n",
    "    return ak.to_packed(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b725bf-45e9-41a9-bad2-9d0fc1cf82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66347fed-495f-4f9a-9f38-6c42325893c7",
   "metadata": {},
   "source": [
    "### Pause a second and talk about performance\n",
    "We're taking a moment to discuss performance, specifically focusing on how time is allocated during different stages of data handling in a particle physics analysis workflow. By examining the time spent reading data into memory and processing it, we gain insights into potential bottlenecks and areas for optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05176d",
   "metadata": {},
   "source": [
    "#### Time for reading arrays into memory\n",
    "It takes approximately 3.29 seconds to read arrays into memory. This measurement gives us a baseline for the time complexity associated with loading data from a file using the specified schema. \n",
    "\n",
    "For this specific example, which involves a relatively small file and a limited number of data branches (fields), a significant portion of the time is not spent on transferring large volumes of data into memory. Instead, it is mostly consumed by metadata operations, such as fetching the TTree object and accessing branch information. This overhead is intrinsic to the file format and the way data is stored and accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b760f5c7-4a6e-4dbb-b73b-86f43a2bfe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit read_events(filename, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e346d1e-5dfe-471b-bfd7-7b640c51d30e",
   "metadata": {},
   "source": [
    "#### Time Spent Opening the File\n",
    "By isolating the action of merely opening the file and accessing the TTree object (only_open()), we find it takes about 1 second. This step does not involve reading any data into memory; it merely sets up access to the data.\n",
    "\n",
    "This result highlights that a significant fraction of the total read time is dedicated to overhead associated with file and data structure access in ROOT files. The implication is that improvements in how metadata is handled could lead to better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0b20fcd6-c439-4955-a5d3-92f663834ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_open():\n",
    "    with uproot.open({filename: \"CollectionTree\"}) as tree:\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5174f231-e5c1-470e-b6bc-e90a20090886",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit only_open()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883f18fb",
   "metadata": {},
   "source": [
    "#### Time Spent on Processing\n",
    "\n",
    "The processing step, quantified by `%timeit processed(events)`, is notably faster, taking only about 170 milliseconds. This difference emphasizes that once the data is in memory, computations and manipulations of the data (such as applying selection criteria and organizing data structures) are highly efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de17d3-3846-4778-8114-4d15dc0c5e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit processed(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28057dc9",
   "metadata": {},
   "source": [
    "The comparison suggests that for small files or when accessing a limited number of branches, the overhead of dealing with metadata can dominate the time spent. This is an important consideration for performance optimization, particularly in workflows that involve many small files or require frequent access to different data branches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f46b1b",
   "metadata": {},
   "source": [
    "## Transforming PHYSLITE into N-Tuple\n",
    "The [N-tuple](https://opendata.atlas.cern/docs/documentation/data_format/ntuple) structure is widely used for physics analyses. One way to use the PHYSLITE files is by transforming it into a N-tuple. For more information on the topic, you can check the [ATLAS Analysis Software Tutorial](https://atlassoftwaredocs.web.cern.ch/ASWTutorial/), particularly [Writing NTuples and Trees using the Text Configuration](https://atlassoftwaredocs.web.cern.ch/AnalysisSWTutorial/cpalg_ntuple/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
