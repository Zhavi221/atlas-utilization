{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c95539ac",
   "metadata": {},
   "source": [
    "Hello\n",
    "Below you will find a tutorial on how to use ATLAS_Parser - a tool made for working with ATLAS Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792ec894",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Important imports\n",
    "from src.parse_atlas import parser, schemas\n",
    "from src.calculations import physics_calcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf858c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Config for the tool\n",
    "config = {\n",
    "    \"max_process_memory_mb\": 8192,\n",
    "    \"max_chunk_size_bytes\": 500_000_000,\n",
    "    \"max_threads\": 3,\n",
    "    \"release_year\": \"2024\",\n",
    "    \"file_limit\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acb09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the parser with configuration\n",
    "atlasparser = parser.ATLAS_Parser(\n",
    "        max_process_memory_mb=config[\"max_process_memory_mb\"],\n",
    "        max_chunk_size_bytes=config[\"max_chunk_size_bytes\"],\n",
    "        max_threads=config[\"max_threads\"]\n",
    "        )\n",
    "\n",
    "#Fetching file URIs for the specified release year\n",
    "release_files_uris = atlasparser.fetch_records_ids(\n",
    "    release_year=config[\"release_year\"]\n",
    ")\n",
    "\n",
    "#Parsing files in chunks and processing events\n",
    "for events_chunk in atlasparser.parse_files(\n",
    "    files_ids=release_files_uris, \n",
    "    limit=config[\"file_limit\"]\n",
    "):\n",
    "    #Here you can do stuff with events_chunk\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26781232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A \n",
    "atlasparser = parser.ATLAS_Parser(\n",
    "        max_process_memory_mb=config[\"max_process_memory_mb\"],\n",
    "        max_chunk_size_bytes=config[\"max_chunk_size_bytes\"],\n",
    "        max_threads=config[\"max_threads\"]\n",
    "        )\n",
    "\n",
    "release_files_uris = atlasparser.fetch_records_ids(\n",
    "    release_year=config[\"release_year\"]\n",
    ")\n",
    "\n",
    "for events_chunk in atlasparser.parse_files(\n",
    "    files_ids=release_files_uris, \n",
    "    limit=config[\"file_limit\"]\n",
    "):\n",
    "        \n",
    "    logger.info(\"Cutting events\")\n",
    "    cut_events = physics_calcs.filter_events_by_kinematics(\n",
    "        events_chunk, config[\"kinematic_cuts\"]\n",
    "    )\n",
    "    del events_chunk  \n",
    "\n",
    "    logger.info(\"Filtering events\")\n",
    "    filtered_events = physics_calcs.filter_events_by_particle_counts(\n",
    "        events=cut_events, \n",
    "        particle_counts=config[\"particle_counts\"], \n",
    "        is_particle_counts_range=True\n",
    "    ) \n",
    "    del cut_events\n",
    "\n",
    "    logger.info(\"Flattening root\")\n",
    "    root_ready = atlasparser.flatten_for_root(filtered_events)\n",
    "    del filtered_events\n",
    "\n",
    "    logger.info(\"Saving events\")\n",
    "    atlasparser.save_events_as_root(root_ready, config[\"output_path\"])        \n",
    "    del root_ready\n",
    "\n",
    "    gc.collect()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1eb010",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAIN GOAL OF THIS, FIGURE OUT IF TAU OR RHO ARE PRESENT\n",
    "import uproot\n",
    "from src.parse_atlas import parser, schemas\n",
    "\n",
    "atlas = parser.ATLAS_Parser(1,1,1)\n",
    "release_files_uris = atlas.fetch_records_ids(\n",
    "    release_year='2024')\n",
    "import random\n",
    "random.shuffle(release_files_uris)\n",
    "keys = []\n",
    "\n",
    "for uri in release_files_uris[:50]:\n",
    "    with uproot.open(uri) as file:\n",
    "        tree = file[\"CollectionTree\"]\n",
    "        keys.extend(tree.keys())\n",
    "        print(f\"Processed {uri}\")\n",
    "    \n",
    "unique_keys = set(keys)\n",
    "[x for x in unique_keys if x.endswith('pt') or x.endswith('tau')]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
