{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Branch Inspection for ATLAS Open Data Releases\n",
        "\n",
        "This notebook inspects branch names for each release year to help configure schemas.\n",
        "\n",
        "Each release may have different branch naming conventions (e.g., `AnalysisElectronsAuxDyn` vs `ElectronAuxDyn`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "import atlasopenmagic as atom\n",
        "import uproot\n",
        "from collections import defaultdict\n",
        "import json\n",
        "from pprint import pprint\n",
        "import sys\n",
        "import os\n",
        "\n",
        "# Add parent directory to path if needed\n",
        "sys.path.insert(0, os.path.abspath('..'))\n",
        "\n",
        "from src.parse_atlas import schemas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Get Available Releases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Available releases:\n",
            "========================================\n",
            "2016e-8tev           2016 Open Data for education release of 8 TeV proton-proton collisions (https://opendata.cern.ch/record/3860).\n",
            "2020e-13tev          2020 Open Data for education release of 13 TeV proton-proton collisions (https://cern.ch/2r7xt).\n",
            "2024r-pp             2024 Open Data for research release for proton-proton collisions (https://opendata.cern.record/80020).\n",
            "2024r-hi             2024 Open Data for research release for heavy-ion collisions (https://opendata.cern.ch/record/80035).\n",
            "2025e-13tev-beta     2025 Open Data for education and outreach beta release for 13 TeV proton-proton collisions (https://opendata.cern.ch/record/93910).\n",
            "2025r-evgen-13tev    2025 Open Data for research release for event generation at 13 TeV (https://opendata.cern.ch/record/160000).\n",
            "2025r-evgen-13p6tev  2025 Open Data for research release for event generation at 13.6 TeV (https://opendata.cern.ch/record/160000).\n",
            "Available releases:\n",
            "  2016e-8tev: 2016 Open Data for education release of 8 TeV proton-proton collisions (https://opendata.cern.ch/record/3860).\n",
            "  2020e-13tev: 2020 Open Data for education release of 13 TeV proton-proton collisions (https://cern.ch/2r7xt).\n",
            "  2024r-pp: 2024 Open Data for research release for proton-proton collisions (https://opendata.cern.record/80020).\n",
            "  2024r-hi: 2024 Open Data for research release for heavy-ion collisions (https://opendata.cern.ch/record/80035).\n",
            "  2025e-13tev-beta: 2025 Open Data for education and outreach beta release for 13 TeV proton-proton collisions (https://opendata.cern.ch/record/93910).\n",
            "  2025r-evgen-13tev: 2025 Open Data for research release for event generation at 13 TeV (https://opendata.cern.ch/record/160000).\n",
            "  2025r-evgen-13p6tev: 2025 Open Data for research release for event generation at 13.6 TeV (https://opendata.cern.ch/record/160000).\n"
          ]
        }
      ],
      "source": [
        "# Get all available releases\n",
        "available_releases = atom.available_releases()\n",
        "print(\"Available releases:\")\n",
        "for release_id, release_info in available_releases.items():\n",
        "    print(f\"  {release_id}: {release_info}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inspect Branches for Each Release\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Objects we're interested in\n",
        "TARGET_OBJECTS = {\"Electrons\", \"Muons\", \"Jets\", \"Photons\"}\n",
        "REQUIRED_FIELDS = {\"pt\", \"eta\", \"phi\"}\n",
        "OPTIONAL_FIELDS = {\"mass\"}\n",
        "\n",
        "# Store results\n",
        "branch_inspection_results = {}\n",
        "\n",
        "# Limit files per release for inspection (to save time)\n",
        "MAX_FILES_PER_RELEASE = 3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "release_branches = dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [],
      "source": [
        "def inspect_branches_for_release(release_id, max_files=3):\n",
        "    \"\"\"\n",
        "    Inspect branch names for a specific release.\n",
        "    \n",
        "    Returns:\n",
        "        dict with branch patterns and detected objects\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"Inspecting release: {release_id}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    try:\n",
        "        # Set the release\n",
        "        atom.set_release(release_id)\n",
        "        \n",
        "        # Get datasets\n",
        "        datasets = atom.available_datasets()\n",
        "        print(f\"Found {len(datasets)} datasets\")\n",
        "        \n",
        "        if not datasets:\n",
        "            return None\n",
        "        \n",
        "        # Get URLs for first few datasets\n",
        "        sample_files = []\n",
        "        for dataset_id in list(datasets)[:max_files]:\n",
        "            try:\n",
        "                urls = atom.get_urls(dataset_id)\n",
        "                if urls:\n",
        "                    sample_files.extend(urls[:1])  # Take first file from each dataset\n",
        "                    if len(sample_files) >= max_files:\n",
        "                        break\n",
        "            except Exception as e:\n",
        "                print(f\"  Warning: Could not get URLs for dataset {dataset_id}: {e}\")\n",
        "                continue\n",
        "        \n",
        "        if not sample_files:\n",
        "            print(f\"  No files found for {release_id}\")\n",
        "            return None\n",
        "        \n",
        "        print(f\"  Inspecting {len(sample_files)} sample files...\")\n",
        "        \n",
        "        # Inspect branches from sample files\n",
        "        all_branches = set()\n",
        "        branch_patterns = defaultdict(set)\n",
        "        detected_objects = {}\n",
        "        for file_url in sample_files[:max_files]:\n",
        "            try:\n",
        "                print(f\"    Opening: {file_url[:80]}...\")\n",
        "                if 'gz' in file_url:\n",
        "                    release_branches[release_id] = \"gzipped\"\n",
        "                    continue\n",
        "                with uproot.open(file_url) as root_file:\n",
        "                    # Find the data tree\n",
        "                    tree_name = None\n",
        "                    for key in root_file.keys():\n",
        "                        if \"CollectionTree\" in key or \"mini\" in key or \"analysis\" in key:\n",
        "                            tree_name = key.split(\";\")[0]  # Remove ';1' suffix\n",
        "                            break\n",
        "                    \n",
        "                    if tree_name is None:\n",
        "                        print(f\"      Warning: No suitable tree found\")\n",
        "                        continue\n",
        "                    \n",
        "                    tree = root_file[tree_name]\n",
        "                    branches = set(tree.keys())\n",
        "                    all_branches.update(branches)\n",
        "                    release_branches[release_id] = list(branches)\n",
        "                    \n",
        "                    # Analyze branch patterns\n",
        "                    for branch in branches:\n",
        "                        # Look for object-related branches\n",
        "                        branch_lower = branch.lower()\n",
        "                        \n",
        "                        # Check for each target object\n",
        "                        for obj_name in TARGET_OBJECTS:\n",
        "                            obj_lower = obj_name.lower()\n",
        "                            if obj_lower in branch_lower:\n",
        "                                # Extract base branch name (before the field)\n",
        "                                if \".\" in branch:\n",
        "                                    base_branch = branch.split(\".\")[0]\n",
        "                                    field = branch.split(\".\")[1]\n",
        "                                    \n",
        "                                    if obj_name not in detected_objects:\n",
        "                                        detected_objects[obj_name] = {\n",
        "                                            \"base_branch\": base_branch,\n",
        "                                            \"fields\": set(),\n",
        "                                            \"all_branches\": []\n",
        "                                        }\n",
        "                                    \n",
        "                                    detected_objects[obj_name][\"fields\"].add(field)\n",
        "                                    detected_objects[obj_name][\"all_branches\"].append(branch)\n",
        "                                    \n",
        "                                    # Store pattern\n",
        "                                    branch_patterns[obj_name].add(base_branch)\n",
        "                                break\n",
        "                    \n",
        "                    print(f\"      Found {len(branches)} branches in tree '{tree_name}'\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"      Error inspecting file: {e}\")\n",
        "                continue\n",
        "        \n",
        "        # Analyze results\n",
        "        result = {\n",
        "            \"release_id\": release_id,\n",
        "            \"total_branches\": len(all_branches),\n",
        "            \"detected_objects\": {},\n",
        "            \"branch_patterns\": {},\n",
        "            \"schema_suggestion\": {}\n",
        "        }\n",
        "        \n",
        "        for obj_name, obj_data in detected_objects.items():\n",
        "            base_branch = obj_data[\"base_branch\"]\n",
        "            fields = sorted(obj_data[\"fields\"])\n",
        "            \n",
        "            # Determine prefix and suffix\n",
        "            # Try to extract pattern: prefix + obj_name + suffix\n",
        "            obj_lower = obj_name.lower()\n",
        "            base_lower = base_branch.lower()\n",
        "            \n",
        "            if obj_lower in base_lower:\n",
        "                idx = base_lower.find(obj_lower)\n",
        "                prefix = base_branch[:idx]\n",
        "                suffix_start = idx + len(obj_name)\n",
        "                suffix = base_branch[suffix_start:] if suffix_start < len(base_branch) else \"\"\n",
        "            else:\n",
        "                prefix = \"\"\n",
        "                suffix = \"\"\n",
        "            \n",
        "            result[\"detected_objects\"][obj_name] = {\n",
        "                \"base_branch\": base_branch,\n",
        "                \"prefix\": prefix,\n",
        "                \"suffix\": suffix,\n",
        "                \"available_fields\": fields,\n",
        "                \"has_required_fields\": REQUIRED_FIELDS.issubset(set(fields)),\n",
        "                \"sample_branches\": obj_data[\"all_branches\"][:5]  # First 5 as examples\n",
        "            }\n",
        "            \n",
        "            result[\"branch_patterns\"][obj_name] = list(branch_patterns[obj_name])\n",
        "        \n",
        "        # Generate schema suggestion\n",
        "        if detected_objects:\n",
        "            # Find common prefix and suffix\n",
        "            prefixes = [obj[\"prefix\"] for obj in result[\"detected_objects\"].values()]\n",
        "            suffixes = [obj[\"suffix\"] for obj in result[\"detected_objects\"].values()]\n",
        "            \n",
        "            common_prefix = prefixes[0] if len(set(prefixes)) == 1 else \"<varies>\"\n",
        "            common_suffix = suffixes[0] if len(set(suffixes)) == 1 else \"<varies>\"\n",
        "            \n",
        "            result[\"schema_suggestion\"] = {\n",
        "                \"branch_prefix\": common_prefix,\n",
        "                \"branch_suffix\": common_suffix,\n",
        "                \"objects\": {}\n",
        "            }\n",
        "            \n",
        "            for obj_name, obj_data in result[\"detected_objects\"].items():\n",
        "                if obj_data[\"has_required_fields\"]:\n",
        "                    # Include required fields + optional if available\n",
        "                    fields_to_include = list(REQUIRED_FIELDS)\n",
        "                    if \"mass\" in obj_data[\"available_fields\"]:\n",
        "                        fields_to_include.append(\"mass\")\n",
        "                    result[\"schema_suggestion\"][\"objects\"][obj_name] = fields_to_include\n",
        "        \n",
        "        return result\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  Error inspecting {release_id}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "Inspecting release: 2016e-8tev\n",
            "================================================================================\n",
            "Fetching and caching all metadata for release: 2016e-8tev...\n",
            "Successfully cached 43 datasets.\n",
            "Active release: 2016e-8tev. (Datasets path: REMOTE)\n",
            "Found 43 datasets\n",
            "  Inspecting 3 sample files...\n",
            "    Opening: root://eospublic.cern.ch//eos/opendata/atlas/OutreachDatasets/2016-07-29/MC/mc_1...\n",
            "      Found 46 branches in tree 'mini'\n",
            "    Opening: root://eospublic.cern.ch//eos/opendata/atlas/OutreachDatasets/2016-07-29/MC/mc_1...\n",
            "      Found 46 branches in tree 'mini'\n",
            "    Opening: root://eospublic.cern.ch//eos/opendata/atlas/OutreachDatasets/2016-07-29/MC/mc_1...\n",
            "      Found 46 branches in tree 'mini'\n",
            "\n",
            "================================================================================\n",
            "Inspecting release: 2020e-13tev\n",
            "================================================================================\n",
            "Fetching and caching all metadata for release: 2020e-13tev...\n",
            "Successfully cached 229 datasets.\n",
            "Active release: 2020e-13tev. (Datasets path: REMOTE)\n",
            "Found 229 datasets\n",
            "  Warning: Could not get URLs for dataset 301215: Skim 'noskim' not found for dataset '301215'. Available skims: 2lep, 3lep, 4lep, exactly2lep\n",
            "  Warning: Could not get URLs for dataset 301216: Skim 'noskim' not found for dataset '301216'. Available skims: 2lep, 3lep, 4lep, exactly2lep\n",
            "  Warning: Could not get URLs for dataset 301217: Skim 'noskim' not found for dataset '301217'. Available skims: 2lep, 3lep, exactly2lep\n",
            "  No files found for 2020e-13tev\n",
            "\n",
            "================================================================================\n",
            "Inspecting release: 2024r-pp\n",
            "================================================================================\n",
            "Fetching and caching all metadata for release: 2024r-pp...\n",
            "Successfully cached 374 datasets.\n",
            "Active release: 2024r-pp. (Datasets path: REMOTE)\n",
            "Found 374 datasets\n",
            "  Inspecting 3 sample files...\n",
            "    Opening: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE...\n",
            "      Found 1554 branches in tree 'CollectionTree'\n",
            "    Opening: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE...\n",
            "      Found 1555 branches in tree 'CollectionTree'\n",
            "    Opening: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE...\n",
            "      Found 1524 branches in tree 'CollectionTree'\n",
            "\n",
            "================================================================================\n",
            "Inspecting release: 2024r-hi\n",
            "================================================================================\n",
            "Fetching and caching all metadata for release: 2024r-hi...\n",
            "Successfully cached 2 datasets.\n",
            "Active release: 2024r-hi. (Datasets path: REMOTE)\n",
            "Found 2 datasets\n",
            "  Inspecting 2 sample files...\n",
            "    Opening: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/mc16_5TeV/DAOD_HION14.41...\n",
            "      Found 278 branches in tree 'CollectionTree'\n",
            "    Opening: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/data15_hi/DAOD_HION14.41...\n",
            "      Found 221 branches in tree 'CollectionTree'\n",
            "\n",
            "================================================================================\n",
            "Inspecting release: 2025e-13tev-beta\n",
            "================================================================================\n",
            "Fetching and caching all metadata for release: 2025e-13tev-beta...\n",
            "Successfully cached 374 datasets.\n",
            "Active release: 2025e-13tev-beta. (Datasets path: REMOTE)\n",
            "Found 374 datasets\n",
            "  Inspecting 3 sample files...\n",
            "    Opening: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/user/egramsta/mc_301204....\n",
            "      Found 116 branches in tree 'analysis'\n",
            "    Opening: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/user/egramsta/mc_301209....\n",
            "      Found 116 branches in tree 'analysis'\n",
            "    Opening: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/user/egramsta/mc_301243....\n",
            "      Found 116 branches in tree 'analysis'\n",
            "\n",
            "================================================================================\n",
            "Inspecting release: 2025r-evgen-13tev\n",
            "================================================================================\n",
            "Fetching and caching all metadata for release: 2025r-evgen-13tev...\n",
            "Successfully cached 5004 datasets.\n",
            "Active release: 2025r-evgen-13tev. (Datasets path: REMOTE)\n",
            "Found 5004 datasets\n",
            "  Inspecting 3 sample files...\n",
            "    Opening: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/mc16_13TeV/HEPMC.4458455...\n",
            "    Opening: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/mc16_13TeV/HEPMC.4639414...\n",
            "    Opening: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/mc16_13TeV/HEPMC.4639414...\n",
            "\n",
            "================================================================================\n",
            "Inspecting release: 2025r-evgen-13p6tev\n",
            "================================================================================\n",
            "Fetching and caching all metadata for release: 2025r-evgen-13p6tev...\n",
            "Successfully cached 1509 datasets.\n",
            "Active release: 2025r-evgen-13p6tev. (Datasets path: REMOTE)\n",
            "Found 1509 datasets\n",
            "  Inspecting 3 sample files...\n",
            "    Opening: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/mc23_13p6TeV/HEPMC.44247...\n",
            "    Opening: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/mc23_13p6TeV/HEPMC.44340...\n",
            "    Opening: root://eospublic.cern.ch:1094//eos/opendata/atlas/rucio/mc23_13p6TeV/HEPMC.44340...\n"
          ]
        }
      ],
      "source": [
        "# Inspect all releases\n",
        "for release_id in available_releases.keys():\n",
        "    result = inspect_branches_for_release(release_id, max_files=MAX_FILES_PER_RELEASE)\n",
        "    if result:\n",
        "        branch_inspection_results[release_id] = result\n",
        "\n",
        "with open(\"branches.json\", \"a\") as f:\n",
        "    json.dump(release_branches, f, indent=2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "BRANCH INSPECTION SUMMARY\n",
            "================================================================================\n",
            "\n",
            "2016e-8tev:\n",
            "  Total branches found: 46\n",
            "  Detected objects: []\n",
            "\n",
            "2024r-pp:\n",
            "  Total branches found: 1563\n",
            "  Detected objects: ['Electrons', 'Jets', 'Muons', 'Photons']\n",
            "  Suggested prefix: '<varies>'\n",
            "  Suggested suffix: 'AuxDyn'\n",
            "  Objects and fields:\n",
            "    Electrons: ['eta', 'phi', 'pt']\n",
            "    Jets: ['eta', 'phi', 'pt']\n",
            "    Muons: ['eta', 'phi', 'pt']\n",
            "    Photons: ['eta', 'phi', 'pt']\n",
            "\n",
            "2024r-hi:\n",
            "  Total branches found: 281\n",
            "  Detected objects: ['Muons']\n",
            "  Suggested prefix: ''\n",
            "  Suggested suffix: 'pectrometerTrackParticlesAuxDyn'\n",
            "  Objects and fields:\n",
            "    Muons: ['eta', 'phi', 'pt']\n",
            "\n",
            "2025e-13tev-beta:\n",
            "  Total branches found: 116\n",
            "  Detected objects: []\n",
            "\n",
            "2025r-evgen-13tev:\n",
            "  Total branches found: 0\n",
            "  Detected objects: []\n",
            "\n",
            "2025r-evgen-13p6tev:\n",
            "  Total branches found: 0\n",
            "  Detected objects: []\n"
          ]
        }
      ],
      "source": [
        "# Print summary for each release\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"BRANCH INSPECTION SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for release_id, result in branch_inspection_results.items():\n",
        "    print(f\"\\n{release_id}:\")\n",
        "    print(f\"  Total branches found: {result['total_branches']}\")\n",
        "    print(f\"  Detected objects: {list(result['detected_objects'].keys())}\")\n",
        "    \n",
        "    if result['schema_suggestion']:\n",
        "        print(f\"  Suggested prefix: '{result['schema_suggestion']['branch_prefix']}'\")\n",
        "        print(f\"  Suggested suffix: '{result['schema_suggestion']['branch_suffix']}'\")\n",
        "        \n",
        "        print(f\"  Objects and fields:\")\n",
        "        for obj_name, fields in result['schema_suggestion']['objects'].items():\n",
        "            print(f\"    {obj_name}: {fields}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "DETAILED RESULTS FOR 2016e-8tev\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "DETAILED RESULTS FOR 2024r-pp\n",
            "================================================================================\n",
            "\n",
            "Electrons:\n",
            "  Base branch: TruthElectronsAuxDyn\n",
            "  Prefix: 'Truth'\n",
            "  Suffix: 'AuxDyn'\n",
            "  Available fields: ['', 'Classification', 'DFCommonElectronsECIDS', 'DFCommonElectronsECIDSResult', 'DFCommonElectronsLHLoose', 'DFCommonElectronsLHLooseBL', 'DFCommonElectronsLHLooseBLIsEMValue', 'DFCommonElectronsLHLooseIsEMValue', 'DFCommonElectronsLHMedium', 'DFCommonElectronsLHMediumIsEMValue', 'DFCommonElectronsLHTight', 'DFCommonElectronsLHTightIsEMValue', 'DFCommonElectronsLHVeryLoose', 'DFCommonElectronsLHVeryLooseIsEMValue', 'OQ', 'TruthLink', 'TruthLink/AnalysisElectronsAuxDyn', 'ambiguityLink', 'ambiguityLink/AnalysisElectronsAuxDyn', 'ambiguityType', 'author', 'barcode', 'caloClusterLinks', 'charge', 'childLinks', 'clEta', 'clPhi', 'classifierParticleOrigin', 'classifierParticleOutCome', 'classifierParticleType', 'd0Normalized', 'decayVtxLink', 'decayVtxLink/TruthElectronsAuxDyn', 'e', 'e_dressed', 'eta', 'eta_dressed', 'etcone20', 'f1', 'firstEgMotherPdgId', 'firstEgMotherTruthOrigin', 'firstEgMotherTruthParticleLink', 'firstEgMotherTruthParticleLink/AnalysisElectronsAuxDyn', 'firstEgMotherTruthType', 'm', 'nInnerExpPix', 'neflowisol20', 'parentLinks', 'pdgId', 'phi', 'phi_dressed', 'polarizationPhi', 'polarizationTheta', 'prodVtxLink', 'prodVtxLink/TruthElectronsAuxDyn', 'pt', 'pt_dressed', 'ptcone20_Nonprompt_All_MaxWeightTTVALooseCone_pt1000', 'ptcone20_Nonprompt_All_MaxWeightTTVALooseCone_pt1000_CloseByCorr', 'ptcone20_Nonprompt_All_MaxWeightTTVALooseCone_pt500', 'ptcone30', 'ptvarcone30_Nonprompt_All_MaxWeightTTVALooseCone_pt1000', 'ptvarcone30_Nonprompt_All_MaxWeightTTVALooseCone_pt1000_CloseByCorr', 'ptvarcone30_Nonprompt_All_MaxWeightTTVALooseCone_pt500', 'px', 'py', 'pz', 'status', 'topoetcone20', 'topoetcone20_CloseByCorr', 'topoetcone20ptCorrection', 'trackParticleLinks', 'truthOrigin', 'truthParticleLink', 'truthParticleLink/AnalysisElectronsAuxDyn', 'truthPdgId', 'truthType', 'z0stheta']\n",
            "  Has required fields: True\n",
            "  Sample branches:\n",
            "    - TruthElectronsAuxDyn.classifierParticleType\n",
            "    - AnalysisElectronsAuxDyn.topoetcone20_CloseByCorr\n",
            "    - AnalysisSiHitElectronsAuxDyn.firstEgMotherTruthType\n",
            "\n",
            "Jets:\n",
            "  Base branch: AnalysisTauJetsAuxDyn\n",
            "  Prefix: 'AnalysisTau'\n",
            "  Suffix: 'AuxDyn'\n",
            "  Available fields: ['', '/AntiKt10TruthSoftDropBeta100Zcut10JetsAux', '/AntiKt10UFOCSSKJetsAux', '/AntiKt4TruthDressedWZJetsAux', 'ActiveArea4vec_eta', 'ActiveArea4vec_m', 'ActiveArea4vec_phi', 'ActiveArea4vec_pt', 'C2', 'ConeTruthLabelID', 'D2', 'DFCommonJets_BCIDDistanceFromFront', 'DFCommonJets_BCIDDistanceTail', 'DFCommonJets_BCIDGapAfterTrain', 'DFCommonJets_BCIDGapAfterTrainMinus12', 'DFCommonJets_BCIDGapBeforeTrain', 'DFCommonJets_BCIDGapBeforeTrainMinus12', 'DFCommonJets_BCIDType', 'DFCommonJets_BCIDTypeMinus12', 'DFCommonJets_QGTagger_NTracks', 'DFCommonJets_QGTagger_TracksC1', 'DFCommonJets_QGTagger_TracksWidth', 'DFCommonJets_eventClean_LooseBad', 'DFCommonJets_eventClean_LooseBadLLP', 'DFCommonJets_fJvt', 'DFCommonJets_isBadBatman', 'DetectorEta', 'ECF1', 'ECF2', 'ECF3', 'EMFrac', 'EleRNNLoose_v1', 'EleRNNMedium_v1', 'EleRNNTight_v1', 'EnergyPerSampling', 'GN2Xv01_phbb', 'GN2Xv01_phcc', 'GN2Xv01_pqcd', 'GN2Xv01_ptop', 'GhostAntiKtVR30Rmax4Rmin02PV0TrackJets', 'GhostBHadronsFinalCount', 'GhostCHadronsFinalCount', 'GhostTrack', 'HadronConeExclExtendedTruthLabelID', 'HadronConeExclTruthLabelID', 'IsTruthMatched', 'JVFCorr', 'JetConstitScaleMomentum_eta', 'JetConstitScaleMomentum_m', 'JetConstitScaleMomentum_phi', 'JetConstitScaleMomentum_pt', 'JetDeepSetLoose', 'JetDeepSetMedium', 'JetDeepSetScore', 'JetDeepSetScoreTrans', 'JetDeepSetTight', 'JetDeepSetVeryLoose', 'NNDecayMode', 'NNJvtPass', 'NumTrkPt1000', 'NumTrkPt500', 'PSFrac', 'PanTau_DecayMode', 'Parent', 'Parent/AnalysisLargeRJetsAuxDyn', 'PartonTruthLabelID', 'Qw', 'R10TruthLabel_R21Precision', 'R10TruthLabel_R21Precision_2022v1', 'R10TruthLabel_R22v1', 'RNNEleScore', 'RNNEleScoreSigTrans_v1', 'RNNJetScore', 'RNNJetScoreSigTrans', 'Split12', 'Split23', 'SumPtChargedPFOPt500', 'SumPtTrkPt500', 'Tau1_wta', 'Tau2_wta', 'Tau3_wta', 'Timing', 'TrackWidthPt1000', 'TrueFlavor', 'Width', 'btaggingLink', 'btaggingLink/AnalysisJetsAuxDyn', 'charge', 'constituentLinks', 'eta', 'etaFinalCalib', 'etaTauEnergyScale', 'isJvtHS', 'isTauFlags', 'm', 'phi', 'pt', 'ptFinalCalib', 'ptTauEnergyScale', 'tauTrackLinks', 'truthJetLink', 'truthJetLink/AnalysisTauJetsAuxDyn', 'truthParticleLink', 'truthParticleLink/AnalysisTauJetsAuxDyn', 'vertexLink', 'vertexLink/AnalysisTauJetsAuxDyn']\n",
            "  Has required fields: True\n",
            "  Sample branches:\n",
            "    - AnalysisTauJetsAuxDyn.RNNEleScore\n",
            "    - AnalysisJetsAuxDyn.NumTrkPt500\n",
            "    - AnalysisJetsAuxDyn.DFCommonJets_fJvt\n",
            "\n",
            "Muons:\n",
            "  Base branch: TruthMuonsAuxDyn\n",
            "  Prefix: 'Truth'\n",
            "  Suffix: 'AuxDyn'\n",
            "  Available fields: ['', 'CaloLRLikelihood', 'CaloMuonIDTag', 'CaloMuonScore', 'Classification', 'DFCommonJetDr', 'DFCommonMuonPassIDCuts', 'DFCommonMuonPassPreselection', 'EnergyLoss', 'GhostMuonSegmentCount', 'InnerDetectorPt', 'MuonSpectrometerPt', 'TruthLink', 'TruthLink/AnalysisMuonsAuxDyn', 'allAuthors', 'author', 'barcode', 'charge', 'childLinks', 'classifierParticleOrigin', 'classifierParticleOutCome', 'classifierParticleType', 'clusterLink', 'clusterLink/AnalysisMuonsAuxDyn', 'combinedTrackOutBoundsPrecisionHits', 'combinedTrackParticleLink', 'combinedTrackParticleLink/AnalysisMuonsAuxDyn', 'cscEtaHits', 'cscUnspoiledEtaHits', 'd0', 'decayVtxLink', 'decayVtxLink/TruthMuonsAuxDyn', 'definingParametersCovMatrixDiag', 'definingParametersCovMatrixOffDiag', 'e', 'e_dressed', 'energyLossType', 'eta', 'eta_dressed', 'etcone20', 'extendedClosePrecisionHits', 'extendedLargeHits', 'extendedLargeHoles', 'extendedOutBoundsPrecisionHits', 'extendedSmallHits', 'extendedSmallHoles', 'extrapolatedMuonSpectrometerTrackParticleLink', 'extrapolatedMuonSpectrometerTrackParticleLink/AnalysisMuonsAuxDyn', 'inDetTrackParticleLink', 'inDetTrackParticleLink/AnalysisMuonsAuxDyn', 'innerClosePrecisionHits', 'innerLargeHits', 'innerLargeHoles', 'innerOutBoundsPrecisionHits', 'innerSmallHits', 'innerSmallHoles', 'isEndcapGoodLayers', 'isSmallGoodSectors', 'm', 'middleClosePrecisionHits', 'middleLargeHits', 'middleLargeHoles', 'middleOutBoundsPrecisionHits', 'middleSmallHits', 'middleSmallHoles', 'momentumBalanceSignificance', 'msOnlyExtrapolatedMuonSpectrometerTrackParticleLink', 'msOnlyExtrapolatedMuonSpectrometerTrackParticleLink/AnalysisMuonsAuxDyn', 'muonSegmentLinks', 'muonSpectrometerTrackParticleLink', 'muonSpectrometerTrackParticleLink/AnalysisMuonsAuxDyn', 'muonType', 'neflowisol20', 'neflowisol20_CloseByCorr', 'numberOfGoodPrecisionLayers', 'numberOfPrecisionHoleLayers', 'numberOfPrecisionLayers', 'outerClosePrecisionHits', 'outerLargeHits', 'outerLargeHoles', 'outerOutBoundsPrecisionHits', 'outerSmallHits', 'outerSmallHoles', 'parentLinks', 'pdgId', 'phi', 'phi_dressed', 'polarizationPhi', 'polarizationTheta', 'prodVtxLink', 'prodVtxLink/TruthMuonsAuxDyn', 'pt', 'pt_dressed', 'ptcone20', 'ptcone20_Nonprompt_All_MaxWeightTTVA_pt1000', 'ptcone20_Nonprompt_All_MaxWeightTTVA_pt500', 'ptcone30', 'ptcone40', 'ptvarcone20', 'ptvarcone30', 'ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt1000', 'ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt1000_CloseByCorr', 'ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt500', 'ptvarcone30_Nonprompt_All_MaxWeightTTVA_pt500_CloseByCorr', 'ptvarcone40', 'px', 'py', 'pz', 'qOverP', 'quality', 'scatteringCurvatureSignificance', 'scatteringNeighbourSignificance', 'segmentDeltaEta', 'spectrometerFieldIntegral', 'status', 'theta', 'topoetcone20', 'topoetcone20_CloseByCorr', 'topoetcone30', 'topoetcone40', 'truthOrigin', 'truthParticleLink', 'truthParticleLink/AnalysisMuonsAuxDyn', 'truthParticleLink/MuonSpectrometerTrackParticlesAuxDyn', 'truthType', 'vz', 'z0']\n",
            "  Has required fields: True\n",
            "  Sample branches:\n",
            "    - TruthMuonsAuxDyn.Classification\n",
            "    - AnalysisMuonsAuxDyn.outerSmallHits\n",
            "    - AnalysisMuonsAuxDyn.outerClosePrecisionHits\n",
            "\n",
            "Photons:\n",
            "  Base branch: TruthPhotonsAuxDyn\n",
            "  Prefix: 'Truth'\n",
            "  Suffix: 'AuxDyn'\n",
            "  Available fields: ['', 'Classification', 'DFCommonPhotonsCleaning', 'DFCommonPhotonsCleaningNoTime', 'DFCommonPhotonsIsEMLoose', 'DFCommonPhotonsIsEMTight', 'DFCommonPhotonsIsEMTightIsEMValue', 'OQ', 'TruthLink', 'TruthLink/AnalysisPhotonsAuxDyn', 'ambiguityLink', 'ambiguityLink/AnalysisPhotonsAuxDyn', 'author', 'barcode', 'caloClusterLinks', 'childLinks', 'classifierParticleOrigin', 'classifierParticleOutCome', 'classifierParticleType', 'decayVtxLink', 'decayVtxLink/TruthPhotonsAuxDyn', 'e', 'eta', 'etcone20', 'etcone40', 'f1', 'm', 'nPhotons_dressed', 'parentLinks', 'pdgId', 'phi', 'polarizationPhi', 'polarizationTheta', 'prodVtxLink', 'prodVtxLink/TruthPhotonsAuxDyn', 'pt', 'ptcone20', 'ptcone20_CloseByCorr', 'px', 'py', 'pz', 'status', 'topoetcone20', 'topoetcone20_CloseByCorr', 'topoetcone20ptCorrection', 'topoetcone40', 'topoetcone40_CloseByCorr', 'topoetcone40ptCorrection', 'truthOrigin', 'truthParticleLink', 'truthParticleLink/AnalysisPhotonsAuxDyn', 'truthType', 'vertexLinks']\n",
            "  Has required fields: True\n",
            "  Sample branches:\n",
            "    - TruthPhotonsAuxDyn.childLinks\n",
            "    - TruthPhotonsAuxDyn.classifierParticleOrigin\n",
            "    - TruthTausAuxDyn.nPhotons_dressed\n",
            "\n",
            "================================================================================\n",
            "DETAILED RESULTS FOR 2024r-hi\n",
            "================================================================================\n",
            "\n",
            "Muons:\n",
            "  Base branch: MuonSpectrometerTrackParticlesAuxDyn\n",
            "  Prefix: ''\n",
            "  Suffix: 'pectrometerTrackParticlesAuxDyn'\n",
            "  Available fields: ['', 'EnergyLoss', 'InnerDetectorPt', 'MuonSpectrometerPt', 'allAuthors', 'author', 'charge', 'combinedTrackOutBoundsPrecisionHits', 'combinedTrackParticleLink', 'combinedTrackParticleLink/MuonsAuxDyn', 'cscUnspoiledEtaHits', 'd0', 'definingParametersCovMatrix', 'energyLossType', 'eta', 'extendedLargeHits', 'extendedSmallHits', 'extendedSmallHoles', 'extrapolatedMuonSpectrometerTrackParticleLink', 'extrapolatedMuonSpectrometerTrackParticleLink/MuonsAuxDyn', 'inDetTrackParticleLink', 'inDetTrackParticleLink/MuonsAuxDyn', 'innerLargeHits', 'innerSmallHits', 'isSmallGoodSectors', 'middleLargeHits', 'middleSmallHits', 'momentumBalanceSignificance', 'muonSpectrometerTrackParticleLink', 'muonSpectrometerTrackParticleLink/MuonsAuxDyn', 'muonType', 'numberOfGoodPrecisionLayers', 'numberOfPrecisionHoleLayers', 'numberOfPrecisionLayers', 'outerLargeHits', 'outerSmallHits', 'phi', 'pt', 'ptcone20', 'ptcone30', 'ptcone40', 'ptvarcone20', 'ptvarcone30', 'ptvarcone40', 'qOverP', 'quality', 'scatteringCurvatureSignificance', 'scatteringNeighbourSignificance', 'theta', 'topoetcone20', 'topoetcone30', 'topoetcone40', 'truthOrigin', 'truthParticleLink', 'truthParticleLink/MuonSpectrometerTrackParticlesAuxDyn', 'truthParticleLink/MuonsAuxDyn', 'truthType', 'vertexLink', 'vertexLink/MuonSpectrometerTrackParticlesAuxDyn', 'vz', 'z0']\n",
            "  Has required fields: True\n",
            "  Sample branches:\n",
            "    - MuonSpectrometerTrackParticlesAuxDyn.truthParticleLink/MuonSpectrometerTrackParticlesAuxDyn.truthParticleLink.m_persKey\n",
            "    - MuonsAuxDyn.truthParticleLink/MuonsAuxDyn.truthParticleLink.m_persIndex\n",
            "    - MuonSpectrometerTrackParticlesAuxDyn.truthParticleLink/MuonSpectrometerTrackParticlesAuxDyn.truthParticleLink.m_persIndex\n",
            "\n",
            "================================================================================\n",
            "DETAILED RESULTS FOR 2025e-13tev-beta\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "DETAILED RESULTS FOR 2025r-evgen-13tev\n",
            "================================================================================\n",
            "\n",
            "================================================================================\n",
            "DETAILED RESULTS FOR 2025r-evgen-13p6tev\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Detailed view for each release\n",
        "for release_id, result in branch_inspection_results.items():\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"DETAILED RESULTS FOR {release_id}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    for obj_name, obj_data in result['detected_objects'].items():\n",
        "        print(f\"\\n{obj_name}:\")\n",
        "        print(f\"  Base branch: {obj_data['base_branch']}\")\n",
        "        print(f\"  Prefix: '{obj_data['prefix']}'\")\n",
        "        print(f\"  Suffix: '{obj_data['suffix']}'\")\n",
        "        print(f\"  Available fields: {obj_data['available_fields']}\")\n",
        "        print(f\"  Has required fields: {obj_data['has_required_fields']}\")\n",
        "        print(f\"  Sample branches:\")\n",
        "        for branch in obj_data['sample_branches'][:3]:\n",
        "            print(f\"    - {branch}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Schema Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "SCHEMA CONFIGURATION CODE\n",
            "================================================================================\n",
            "\n",
            "# Add this to schemas.py RELEASE_SCHEMAS dictionary:\n",
            "\n",
            "    \"2024r-pp\": {\n",
            "        \"branch_prefix\": \"<varies>\",\n",
            "        \"branch_suffix\": \"AuxDyn\",\n",
            "        \"objects\": {\n",
            "            \"Electrons\": [\"eta\", \"phi\", \"pt\"],\n",
            "            \"Jets\": [\"eta\", \"phi\", \"pt\"],\n",
            "            \"Muons\": [\"eta\", \"phi\", \"pt\"],\n",
            "            \"Photons\": [\"eta\", \"phi\", \"pt\"],\n",
            "        }\n",
            "    },\n",
            "\n",
            "    \"2024r-hi\": {\n",
            "        \"branch_prefix\": \"\",\n",
            "        \"branch_suffix\": \"pectrometerTrackParticlesAuxDyn\",\n",
            "        \"objects\": {\n",
            "            \"Muons\": [\"eta\", \"phi\", \"pt\"],\n",
            "        }\n",
            "    },\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Generate Python code for schema configuration\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SCHEMA CONFIGURATION CODE\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n# Add this to schemas.py RELEASE_SCHEMAS dictionary:\\n\")\n",
        "\n",
        "for release_id, result in branch_inspection_results.items():\n",
        "    if result['schema_suggestion']:\n",
        "        schema = result['schema_suggestion']\n",
        "        \n",
        "        print(f\"    \\\"{release_id}\\\": {{\")\n",
        "        print(f\"        \\\"branch_prefix\\\": \\\"{schema['branch_prefix']}\\\",\")\n",
        "        print(f\"        \\\"branch_suffix\\\": \\\"{schema['branch_suffix']}\\\",\")\n",
        "        print(f\"        \\\"objects\\\": {{\")\n",
        "        \n",
        "        for obj_name, fields in schema['objects'].items():\n",
        "            fields_str = ', '.join([f'\"{f}\"' for f in fields])\n",
        "            print(f\"            \\\"{obj_name}\\\": [{fields_str}],\")\n",
        "        \n",
        "        print(f\"        }}\")\n",
        "        print(f\"    }},\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Results saved to branch_inspection_results.json\n"
          ]
        }
      ],
      "source": [
        "# Save results to JSON file\n",
        "output_file = \"branch_inspection_results.json\"\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(branch_inspection_results, f, indent=2)\n",
        "\n",
        "print(f\"\\nResults saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare with Current Schema\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "COMPARISON WITH CURRENT SCHEMAS\n",
            "================================================================================\n",
            "\n",
            "2016e-8tev:\n",
            "  Current schema exists: ✓\n",
            "    Prefix: 'Analysis'\n",
            "    Suffix: 'AuxDyn'\n",
            "\n",
            "2024r-pp:\n",
            "  Current schema exists: ✓\n",
            "    Prefix: 'Analysis'\n",
            "    Suffix: 'AuxDyn'\n",
            "    ⚠ Prefix mismatch: current='Analysis', detected='<varies>'\n",
            "\n",
            "2024r-hi:\n",
            "  Current schema exists: ✓\n",
            "    Prefix: 'Analysis'\n",
            "    Suffix: 'AuxDyn'\n",
            "    ⚠ Prefix mismatch: current='Analysis', detected=''\n",
            "    ⚠ Suffix mismatch: current='AuxDyn', detected='pectrometerTrackParticlesAuxDyn'\n",
            "\n",
            "2025e-13tev-beta:\n",
            "  Current schema exists: ✓\n",
            "    Prefix: 'Analysis'\n",
            "    Suffix: 'AuxDyn'\n",
            "\n",
            "2025r-evgen-13tev:\n",
            "  Current schema exists: ✓\n",
            "    Prefix: 'Analysis'\n",
            "    Suffix: 'AuxDyn'\n",
            "\n",
            "2025r-evgen-13p6tev:\n",
            "  Current schema exists: ✓\n",
            "    Prefix: 'Analysis'\n",
            "    Suffix: 'AuxDyn'\n"
          ]
        }
      ],
      "source": [
        "# Compare detected patterns with current schema\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPARISON WITH CURRENT SCHEMAS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for release_id, result in branch_inspection_results.items():\n",
        "    print(f\"\\n{release_id}:\")\n",
        "    \n",
        "    try:\n",
        "        current_schema = schemas.get_schema_for_release(release_id)\n",
        "        print(f\"  Current schema exists: ✓\")\n",
        "        print(f\"    Prefix: '{current_schema['branch_prefix']}'\")\n",
        "        print(f\"    Suffix: '{current_schema['branch_suffix']}'\")\n",
        "        \n",
        "        if result['schema_suggestion']:\n",
        "            detected_prefix = result['schema_suggestion']['branch_prefix']\n",
        "            detected_suffix = result['schema_suggestion']['branch_suffix']\n",
        "            \n",
        "            prefix_match = current_schema['branch_prefix'] == detected_prefix\n",
        "            suffix_match = current_schema['branch_suffix'] == detected_suffix\n",
        "            \n",
        "            if not prefix_match:\n",
        "                print(f\"    ⚠ Prefix mismatch: current='{current_schema['branch_prefix']}', detected='{detected_prefix}'\")\n",
        "            if not suffix_match:\n",
        "                print(f\"    ⚠ Suffix mismatch: current='{current_schema['branch_suffix']}', detected='{detected_suffix}'\")\n",
        "            \n",
        "            if prefix_match and suffix_match:\n",
        "                print(f\"    ✓ Schema matches detected pattern\")\n",
        "    \n",
        "    except KeyError:\n",
        "        print(f\"  Current schema: ✗ (not found)\")\n",
        "        if result['schema_suggestion']:\n",
        "            print(f\"  → Use detected pattern: prefix='{result['schema_suggestion']['branch_prefix']}', suffix='{result['schema_suggestion']['branch_suffix']}'\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
