{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff11ca7-aab1-492b-90c1-1fc5d00faa22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-29T15:37:46.731901Z",
     "start_time": "2025-06-29T15:37:44.305593Z"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import copy # copy variables\n",
    "import os   # manage paths\n",
    "\n",
    "import uproot   # use of root files\n",
    "import awkward as ak    # nested, variable sized data\n",
    "import vector   # lorentz vectors\n",
    "vector.register_awkward()\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import atlasopenmagic as atom\n",
    "\n",
    "from src.parse_atlas import (parser, consts, schemas, combinatorics)\n",
    "\n",
    "import traceback\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52b41e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING MC files\n",
    "mc_rec_id = atlasparser.fetch_mc_files_ids('2024', is_random=True)\n",
    "all_metadata = atom.get_metadata(mc_rec_id)\n",
    "urls = atom.get_urls(mc_rec_id)\n",
    "atlasparser.parsing_pipeline(schemas.GENERIC_SCHEMA, files_ids=urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7439f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TESTING MAIN PIPELINE\n",
    "import main_pipeline\n",
    "\n",
    "main_pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6579ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST FOR KEYS OF ROOT FILE\n",
    "from src.parse_atlas import parser, schemas\n",
    "import atlasopenmagic as atom\n",
    "parse = parser.ATLAS_Parser()\n",
    "rand_id = parse.fetch_mc_files_ids(\n",
    "    '2024', is_random=True)\n",
    "uri = atom.get_urls(rand_id)[0]\n",
    "# testing = parse.testing_load_file_as_object(uri)\n",
    "testing = parse._parse_file(\n",
    "    schema=schemas.GENERIC_SCHEMA, \n",
    "    file_index=uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a76cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(testing)\n",
    "testing.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b48991-4b0c-4b3a-a23e-00e285c71b4b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:09:40.129899Z",
     "start_time": "2025-06-21T17:09:40.028552Z"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "GeV = 1000.\n",
    "\n",
    "def selected_electrons(el):\n",
    "    return el[(el.pt > 10 * GeV) & (abs(el.eta) < 2.47)]\n",
    "\n",
    "def selected_muons(mu):\n",
    "    return mu[(mu.pt > 10 * GeV) & (abs(mu.eta) < 2.47)]\n",
    "\n",
    "def selected_jets(j):\n",
    "    return j[(j.pt > 10 * GeV) & (abs(j.eta) < 2.47)]\n",
    "\n",
    "def no_overlap(obj1, obj2, deltaR=0.4):\n",
    "    obj1, obj2 = ak.unzip(ak.cartesian([obj1, obj2], nested=True))\n",
    "    return ak.all(obj1.deltaR(obj2) > deltaR, axis=-1)\n",
    "\n",
    "def mjjj(jets):\n",
    "    candidates = ak.combinations(jets, 3)\n",
    "    j1, j2, j3 = ak.unzip(candidates)\n",
    "    candidates[\"p4\"] = j1 + j2 + j3\n",
    "    candidates = candidates[ak.argmax(candidates.p4.pt, axis=1, keepdims=True)]\n",
    "    return candidates.p4.mass\n",
    "\n",
    "def processed(events):\n",
    "    events = copy.copy(events) # shallow copy\n",
    "    events[\"Electrons\"] = selected_electrons(events.Electrons)\n",
    "    events[\"Muons\"] = selected_muons(events.Muons)\n",
    "    events[\"Jets\"] = selected_jets(events.Jets)\n",
    "    events[\"Jets\"] = events.Jets[no_overlap(events.Jets, events.Electrons)]\n",
    "    events = events[\n",
    "        (ak.num(events.Jets) >= 4) # at least 4 jets\n",
    "        & ((ak.num(events.Electrons) + ak.num(events.Muons)) == 1) # exactly one lepton\n",
    "    ]\n",
    "    return ak.to_packed(events)\n",
    "\n",
    "events = processed(atlasparser.events)\n",
    "plt.hist(ak.flatten(mjjj(events.Jets) / GeV, axis=None), bins=100)\n",
    "plt.xlabel(\"Reconstructed Top Quark Mass (GeV)\")\n",
    "plt.ylabel(\"Number of Events\")\n",
    "plt.title(\"Distribution of Reconstructed Top Quark Mass\")\n",
    "plt.axvline(172.76, color='r', linestyle='dashed', linewidth=2, label='Expected Top Quark Mass')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Total events:', len(atlasparser.events))\n",
    "print('Events after filtering:', len(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bbd7e9-30d8-4976-a96d-e9f692838c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def selected_electrons(el):\n",
    "    return el[(el.pt > 10 * GeV) & (abs(el.eta) < 2.47)]\n",
    "\n",
    "def electron_posi_muon_antimuon(events):\n",
    "    events = copy.copy(events) # shallow copy\n",
    "    events[\"Electrons\"] = selected_electrons(events.Electrons)\n",
    "    events[\"Muons\"] = selected_muons(events.Muons)\n",
    "    events[\"Electrons\", \"is_neg\"] = events.Electrons.charge < 0\n",
    "    events[\"Muons\", \"is_neg\"] = events.Muons.charge < 0\n",
    "    events = events[\n",
    "        (ak.num(events.Electrons) == 2) \n",
    "        & (ak.num(events.Muons) == 2)\n",
    "        # & (ak.num(events.Electrons[events.Electrons.is_neg]) == 1)\n",
    "        # & (ak.num(events.Muons[events.Muons.is_neg]) == 1)\n",
    "    ]\n",
    "    return ak.to_packed(events)\n",
    "\n",
    "events = electron_posi_muon_antimuon(atlasparser.events)\n",
    "plt.hist(ak.flatten(events) / GeV, axis=None, bins=100)\n",
    "plt.xlabel(\"Reconstructed Top Quark Mass (GeV)\")\n",
    "plt.ylabel(\"Number of Events\")\n",
    "plt.title(\"Distribution of Reconstructed Top Quark Mass\")\n",
    "plt.axvline(172.76, color='r', linestyle='dashed', linewidth=2, label='Expected Top Quark Mass')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Total events:', len(atlasparser.events))\n",
    "print('Events after filtering:', len(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.parse_atlas import combinatorics, schemas\n",
    "\n",
    "categories = combinatorics.make_objects_categories(schemas.PARTICLE_LIST, min_n=4, max_n=4)\n",
    "print(json.dumps(categories, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51640c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000001.pool.root.1', 'root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000002.pool.root.1', 'root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000003.pool.root.1', 'root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000004.pool.root.1', 'root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000005.pool.root.1', 'root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000006.pool.root.1', 'root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000008.pool.root.1', 'root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000007.pool.root.1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing file: 100%|██████████| 1/1 [00:00<00:00,  1.05batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{Jets: [], Photons: []}, {Jets: [], ...}, ..., {...}, {Jets: [], Photons: []}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing file: 100%|██████████| 1/1 [00:00<00:00,  2.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{Jets: [], Photons: []}, {Jets: [], ...}, ..., {...}, {Jets: [], Photons: []}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing file: 100%|██████████| 1/1 [00:01<00:00,  1.08s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{Jets: [], Photons: []}, {Jets: [], ...}, ..., {...}, {Jets: [], Photons: []}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing file: 100%|██████████| 1/1 [00:01<00:00,  1.07s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{Jets: [], Photons: []}, {Jets: [], ...}, ..., {...}, {Jets: [], Photons: []}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing file: 100%|██████████| 1/1 [00:00<00:00,  1.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{Jets: [], Photons: []}, {Jets: [], ...}, ..., {...}, {Jets: [], Photons: []}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing file: 100%|██████████| 1/1 [00:00<00:00,  1.21batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{Jets: [], Photons: []}, {Jets: [], ...}, ..., {...}, {Jets: [], Photons: []}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing file: 100%|██████████| 1/1 [00:00<00:00,  1.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{Jets: [], Photons: []}, {Jets: [], ...}, ..., {...}, {Jets: [], Photons: []}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing file: 100%|██████████| 1/1 [00:00<00:00,  1.18batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{Jets: [], Photons: []}, {Jets: [], ...}, ..., {...}, {Jets: [], Photons: []}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import uproot\n",
    "from src.parse_atlas import parser\n",
    "\n",
    "rootfile = \"data/root_files/04c909a9fe9756a7.root\"\n",
    "\n",
    "with uproot.open(rootfile) as file:\n",
    "    tree = file[file.keys()[0]]\n",
    "    \n",
    "    files = file['metadata']['file_ids'].array()\n",
    "\n",
    "files = files[0].split(',')\n",
    "\n",
    "print(files)\n",
    "for file_id in files:\n",
    "    parsed = parser.ATLAS_Parser.parse_file(files[0])\n",
    "    print(parsed)\n",
    "    if len(parsed) == 0:\n",
    "        print(file_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38476ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.parse_atlas import parser, schemas\n",
    "\n",
    "atlas = parser.ATLAS_Parser()\n",
    "release_files_uris = atlas.fetch_mc_files_ids(\n",
    "    release_year='2024')\n",
    "\n",
    "with open(\"configs/file_ids_2024\", \"w+\") as f:\n",
    "    f.write(\"\\n\".join(release_files_uris))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e22374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trying file: root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000001.pool.root.1\n",
      "trying file: root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000002.pool.root.1\n",
      "trying file: root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000003.pool.root.1\n",
      "trying file: root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000004.pool.root.1\n",
      "trying file: root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000005.pool.root.1\n",
      "trying file: root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000006.pool.root.1\n",
      "trying file: root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000007.pool.root.1\n",
      "trying file: root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000008.pool.root.1\n",
      "trying file: root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000009.pool.root.1\n",
      "trying file: root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000010.pool.root.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing file as batches: 100%|██████████| 45/45 [03:46<00:00,  5.04s/batch]\n",
      "Parsing file as batches: 100%|██████████| 23/23 [03:59<00:00, 10.43s/batch]\n",
      "Parsing file as batches: 100%|██████████| 15/15 [03:57<00:00, 15.82s/batch]\n",
      "Parsing file as batches: 100%|██████████| 12/12 [04:16<00:00, 21.41s/batch]\n",
      "Parsing file as batches: 100%|██████████| 9/9 [03:52<00:00, 25.81s/batch]\n",
      "Parsing file as batches: 100%|██████████| 8/8 [03:39<00:00, 27.42s/batch]\n",
      "Parsing file as batches: 100%|██████████| 7/7 [03:54<00:00, 33.45s/batch]\n",
      "Parsing file as batches:  67%|██████▋   | 4/6 [02:24<01:13, 36.91s/batch]"
     ]
    }
   ],
   "source": [
    "from src.parse_atlas import parser, schemas\n",
    "import argparse, yaml, uproot\n",
    "import time\n",
    "\n",
    "atlasparser = parser.ATLAS_Parser(0, 10000, 10000)\n",
    "ids = atlasparser.fetch_records_ids('2024')\n",
    "list_of_times = {}\n",
    "try:\n",
    "    for id in ids:\n",
    "        print('trying file:', id)\n",
    "        with uproot.open({id: \"CollectionTree\"}) as file:\n",
    "            tree = file[file.keys()[0]]\n",
    "            all_keys = tree.keys()\n",
    "            n_entries = tree.num_entries\n",
    "            if n_entries < 50_000:\n",
    "                continue\n",
    "\n",
    "            for entries in range(5000, 100000, 5000):\n",
    "                start_time = time.time()\n",
    "                parser.ATLAS_Parser.parse_file(\n",
    "                    # \"root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000012.pool.root.1\", \n",
    "                    id,\n",
    "                    batch_size=entries)\n",
    "                time_taken = time.time() - start_time\n",
    "                list_of_times[str(entries)] = time_taken\n",
    "except:\n",
    "    print('failed on file:', id)\n",
    "    print(list_of_times)\n",
    "    print(min(list_of_times, key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05e7d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your invariant masses (replace with your actual array)\n",
    "inv_masses = inv_mass  # The 45,372 values you computed\n",
    "\n",
    "# Create histogram\n",
    "n_bins = 100  # Adjust based on your needs\n",
    "mass_min, mass_max = 0, 5000000  # Adjust range as needed\n",
    "\n",
    "bin_content, bin_edges = np.histogram(inv_masses, bins=n_bins, range=(mass_min, mass_max))\n",
    "bin_errors = np.sqrt(bin_content)  # Poisson errors\n",
    "\n",
    "# Create the data structure your smoothing script expects\n",
    "histogram_data = {\n",
    "    'names': ['invariant_mass_distribution'],\n",
    "    'bin_content': [bin_content],\n",
    "    'bin_edges': [bin_edges],\n",
    "    'bin_errors': [bin_errors]\n",
    "}\n",
    "\n",
    "# Save in the format your script expects\n",
    "output_dir = 'BumpNet-main/baseline/histograms_test'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# np.save(f'{output_dir}/names.npy', np.array(histogram_data['names'], dtype=object))\n",
    "# np.save(f'{output_dir}/bin_content.npy', np.array(histogram_data['bin_content'], dtype=object))\n",
    "# np.save(f'{output_dir}/bin_edges.npy', np.array(histogram_data['bin_edges'], dtype=object))\n",
    "# np.save(f'{output_dir}/bin_errors.npy', np.array(histogram_data['bin_errors'], dtype=object))\n",
    "\n",
    "print(f\"Saved histogram data to {output_dir}/\")\n",
    "\n",
    "print(f\"Number of events: {len(inv_mass)}\")\n",
    "print(f\"Mean invariant mass: {np.mean(inv_mass):.2f}\")\n",
    "print(f\"Median invariant mass: {np.median(inv_mass):.2f}\")\n",
    "print(f\"Standard deviation: {np.std(inv_mass):.2f}\")\n",
    "print(f\"Minimum invariant mass: {np.min(inv_mass):.2f}\")\n",
    "print(f\"Maximum invariant mass: {np.max(inv_mass):.2f}\")\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.hist(bin_edges[:-1], bins=bin_edges, weights=bin_content, alpha=0.7, label='Invariant Mass')\n",
    "plt.errorbar((bin_edges[:-1] + bin_edges[1:]) / 2, bin_content, yerr=bin_errors, fmt='.', color='black', label='Poisson error')\n",
    "plt.xlabel('Invariant Mass')\n",
    "plt.ylabel('Events')\n",
    "plt.title('Invariant Mass Distribution')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e501cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "\n",
    "with uproot.open(\"root://eospublic.cern.ch//eos/opendata/atlas/rucio/data15_13TeV/DAOD_PHYSLITE.37001626._000014.pool.root.1\") as file:\n",
    "    print(file.keys())\n",
    "    print(file['MetaData'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4111a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
